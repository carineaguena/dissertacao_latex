%% Template para dissertação/tese na classe UFPEthesis
%% versão 0.9.2
%% (c) 2005 Paulo G. S. Fonseca
%% www.cin.ufpe.br/~paguso/ufpethesis

%% Carrega a classe ufpethesis
%% Opções: * Idiomas
%%           pt   - português (padrão)
%%           en   - inglês
%%         * Tipo do Texto
%%           bsc  - para monografias de graduação
%%           msc  - para dissertações de mestrado (padrão)
%%           qual - exame de qualificação doutorado
%%           prop - proposta de tese doutorado
%%           phd  - para teses de doutorado
%%         * Mídia
%%           scr  - para versão eletrônica (PDF) / consulte o guia do usuario
%%         * Estilo
%%           classic - estilo original à la TAOCP (deprecated)
%%           std     - novo estilo à la CUP (padrão)
%%         * Paginação
%%           oneside - para impressão em face única
%%           twoside - para impressão em frente e verso (padrão)
\documentclass{ufpethesis}

%% Preâmbulo:
%% coloque aqui o seu preâmbulo LaTeX, i.e., declaração de pacotes,
%% (re)definições de macros, medidas, etc.

%% Identificação:

% Universidade
% e.g. \university{Universidade de Campinas}
% Na UFPE, comente a linha a seguir
%\university{<NOME DA UNIVERSIDADE>}

% Endereço (cidade)
% e.g. \address{Campinas}
% Na UFPE, comente a linha a seguir
%\address{<CIDADE DA IES>}

% Instituto ou Centro Acadêmico
% e.g. \institute{Centro de Ciências Exatas e da Natureza}
% Comente se não se aplicar
\institute{Cin - Centro de Informática}

% Departamento acadêmico
% e.g. \department{Departamento de Informática}
% Comente se não se aplicar
%\department{<NOME DO DEPARTAMENTO>}

% Programa de pós-graduação
% e.g. \program{Pós-graduação em Ciência da Computação}
\program{Pós graduação em Ciência da Computação}

% Área de titulação
% e.g. \majorfield{Ciência da Computação}
\majorfield{Ciência da Computação}

% Título da dissertação/tese
% e.g. \title{Sobre a conjectura $P=NP$}
\title{ETL4NoSQL: Um framework de ETL para BDs NoSQL}

% Data da defesa
% e.g. \date{19 de fevereiro de 2003}
\date{<DATA DA DEFESA>}

% Autor
% e.g. \author{José da Silva}
\author{Carine Calixto Aguena}

% Orientador(a)
% Opção: [f] - para orientador do sexo feminino
% e.g. \adviser[f]{Profa. Dra. Maria Santos}
\adviser{Valéria Cesário Times}

% Orientador(a)
% Opção: [f] - para orientador do sexo feminino
% e.g. \coadviser{Prof. Dr. Pedro Pedreira}
% Comente se não se aplicar
%\coadviser{NOME DO(DA) CO-ORIENTADOR(A)}

%% Inicio do documento
\begin{document}


%%
%% Parte pré-textual
%%
\frontmatter

% Folha de rosto
% Comente para ocultar
\frontpage

% Portada (apresentação)
% Comente para ocultar
\presentationpage

% Dedicatória
% Comente para ocultar
\begin{dedicatory}
<DIGITE A DEDICATÒRIA AQUI>
\end{dedicatory}

% Agradecimentos
% Se preferir, crie um arquivo à parte e o inclua via \include{}
\acknowledgements
<DIGITE OS AGRADECIMENTOS AQUI>

% Epígrafe
% Comente para ocultar
% e.g.
%  \begin{epigraph}[Tarde, 1919]{Olavo Bilac}
%  Última flor do Lácio, inculta e bela,\\
%  És, a um tempo, esplendor e sepultura;\\
%  Ouro nativo, que, na ganga impura,\\
%  A bruta mina entre os cascalhos vela.
%  \end{epigraph}
\begin{epigraph}[<NOTA>]{<AUTOR>}
<DIGITE AQUI A CITAÇÂO>
\end{epigraph}

% Resumo em Português
% Se preferir, crie um arquivo à parte e o inclua via \include{}
\resumo
<DIGITE O RESUMO AQUI>
% Palavras-chave do resumo em Português
\begin{keywords}
<DIGITE AS PALAVRAS-CHAVE AQUI>
\end{keywords}

% Resumo em Inglês
% Se preferir, crie um arquivo à parte e o inclua via \include{}
\abstract
% Palavras-chave do resumo em Inglês
\begin{keywords}
<DIGITE AS PALAVRAS-CHAVE AQUI>
\end{keywords}

% Sumário
% Comente para ocultar
%\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents

% Lista de figuras
% Comente para ocultar
\listoffigures

% Lista de tabelas
% Comente para ocultar
\listoftables



%%
%% Parte textual
%%
\mainmatter

% É aconselhável criar cada capítulo em um arquivo à parte, digamos
% "capitulo1.tex", "capitulo2.tex", ... "capituloN.tex" e depois
% incluí-los com:
% \include{capitulo1}
% \include{capitulo2}
% ...
% \include{capituloN}

 \pagestyle{fancy}
 \fancyhead[RE,RO]{\thepage}
\fancyhead[LE,LO]{\leftmark}
\fancyfoot[RE,RO]{C. C. Aguena}
\fancyfoot[LE,LO]{ETL4NoSQL: Um Framework de ETL para BDs NoSQL}
\fancyfoot[CE,CO]{}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{1pt}


\chapter{Introdução}
\noindent Este capítulo contextualiza os principais assuntos abordados neste trabalho, apresenta as motivações, os objetivos gerais e específicos da proposta desta pesquisa, bem como sua justificativa.
\clearpage

% ----------------------------------------------------------
% seção
% ----------------------------------------------------------

\section{Contextualização}
% ----------------------------------------------------------

Os requisitos para ferramentas de software modernas têm mudado significativamente, especialmente com o aumento das aplicações Web. Este segmento de aplicações exige requisitos com alta escalabilidade e vazão, onde sistemas que utilizam um armazenamento com esquema relacional não conseguem atender satisfatoriamente. Em resposta a isso, novas abordagens de armazenamentos de dados utilizando o termo de NoSQL tornaram-se popular.

O termo NoSQL é constantemente interpretado como  ''\emph{Not Only SQL}'', cujo SQL refere-se a linguagem de manipulação de dados dos gerenciadores de armazenamento de dados relacionais (RDBMS - Relational Database Management System) - Structure Query Language. O grande propósito das abordagens NoSQL é oferecer alternativas onde os esquemas relacionais não funcionam bem. Esse termo abrange diferentes tipos de sistemas. Em geral, banco de dados NoSQL usam modelo de dados não-relacionais, com poucas definições de esquema e escala horizontal \cite{nasholm:2012}.

Muitas empresas coletam e armazenam milhares de gigabytes de dados por dia, no qual a analise desses dados torna-se uma vantagem competitiva no mercado. Dessa forma, há uma grande necessidade de uma nova arquitetura de Data Warehouse que possa alcançar melhor escalabilidade e eficiência \cite{liu:2013}.

Segundo a definição de \cite{kimball:2002}, Data Warehouse (DW) é uma coleção de dados para o processo de gerenciamento de suporte à decisão orientado a assunto, integrado, variante no tempo e não volátil. Os dados de diferentes fontes de sistemas são processados em um Data Warehouse central através da Extração, Transformação e Carga (ETL) de maneira periódica. 

O projeto de ETL consome cerca de 70\% dos recursos de implantação de um DW, pois desenvolver esse projeto é crítico e custoso, tendo em vista que gerar dados incorretos pode acarretar em más decisões. Porém, pouca importância foi dada ao processo de ETL por um grande período de tempo pelo fato de ser visto somente como uma atividade de suporte aos projetos de DW. Apenas a partir do ano 2000, a comunidade acadêmica passou a dar mais importância ao tema \cite{silva:2012}.

As pesquisas passaram a apontar problemas como complexidade, longa curva de aprendizagem, notações proprietárias, custo e tempo de implantação das ferramentas atuais. Além disso, é impossível oferecer um pacote fechado com todas as possibilidades de transformações exigidas pelos processos de ETL. Para sanar essas dificuldades, propostas de modelagens conceituais e lógicas foram apresentadas e Notação de Modelagem para Processo de Negócio (BPMN) para ETL foram definidas, as quais aumentam o nível de abstração dos processos de ETL, e consequentemente, os tornam independentes da plataforma de implementação. Contudo, a implementação dos processos de ETL programaticamente a partir de uma linguagem de programação de propósito geral tem sido adotada por muitas empresas, porque isso evita as desvantagens da utilização de ferramentas, além de aumentar o nível de customização e integração dos processos de ETL com outros sistemas \cite{silva:2012}. 

Tradicionalmente, o DW é implementado em uma base de dados relacional, onde o dado é armazenado nas tabelas fato e tabelas dimensões, na qual forma um esquema em estrela (colocar ref DW). Por isso, é comum que as ferramentas de ETL utilizadas no mercado atualmente só dêem suporte aos esquemas relacionais. Para dar suporte aos sistemas que necessitem utilizar um esquema não relacional em DW, a proposta desse trabalho é especificar um framework programável, flexível e integrado para modelagem e execução de processos ETL em BDs NoSQL.

% ---
% Capitulo com exemplos de comandos inseridos de arquivo externo 
% ---
%\include{abntex2-modelo-include-comandos}
% ---

% ----------------------------------------------------------
% seção
% ----------------------------------------------------------
\section{Motivação}
% ----------------------------------------------------------

O aumento do uso de Banco de Dados com esquemas não relacionais e a falta de uma ferramenta programável, flexível e integrada, independente de plataforma que dê suporte à extração, transformação e carga em Data Warehouses é a grande motivação deste trabalho.

As pesquisas sobre extração de dados em BDs NoSQL mostram que não há uma ferramenta que seja integrada para o uso de BDs NoSQL, as ferramentas existentes no mercado apenas oferecem a possibilidade para alguns SGBDs NoSQL, ficando a cargo da equipe de implantação do projeto de DW todo o trabalho de modelagem e programação ao se utilizar BDs NoSQL.

\cite{silva:2012} aponta em sua pesquisa que muitas empresas evitam ferramentas de ETL disponíveis no mercado, e adotam o desenvolvimento dos processos a partir de uma linguagem de programação de propósito geral, pelo fato dessas ferramentas terem uma longa curva de aprendizagem e grande complexidade no seu uso.

Dessa forma, encontrar uma solução que seja programável, flexível e integrada para extração, transformação e carga dos dados em BDs NoSQL é a motivação deste trabalho.





% ----------------------------------------------------------
% Seção
% ----------------------------------------------------------
\section{Objetivos}

Nesta seção serão apresentados os objetivos geral e específicos desta pesquisa.
% ----------------------------------------------------------
\subsection{Objetivo Geral}

Especificar um framework programável, flexível e integrado para modelagem e execução de processos ETL em BDs NoSQL.

\subsection{Objetivo Específico}

Estender a proposta do framework para facilitar a carga de dados de dois sistemas de BD NoSQL distintos baseado no paradigma família de coluna em um DW relacional.

\section{Justificativa}




\section{Organização do Trabalho}


% ---
% Capitulo de revisão de literatura
% ---
\chapter{Fundamentação Teórica}
% ---

Neste capítulo são apresentados os conceitos relacionados ao desenvolvimento desta pesquisa. 

Os conceitos de ETL e Data Warehouse (DW), bem como o termo NoSQL e os paradigmas de esquemas não relacionais mais utilizados pela comunidade acadêmica, o Famílias de Colunas, Orientados à Documentos, Chave-Valor e Baseado em Grafos.

 Também são detalhadas as definições de modelagem conceitual e lógica para esquemas não relacionais.

\clearpage
% ---

\section{ETL}

\section{Data Warehouse}

\section{Bancos de Dados NoSQL}

Consistem em bancos de dados não relacionais projetados para gerenciar grandes volumes de dados e que disponibilizam estruturas e interfaces de acesso simples (Lima; Mello, 2015). Cada paradigma NoSQL possui um esquema de modelagem diferente, nos quais são divididas pela literatura em quatro categorias amplamente usadas: Chave-Valor, Orientado a Documentos, Famílias de Colunas e Baseado em Grafos ([Fowler, 2013], [Kaur; Rani, 2013]).

As principais características dos banco de dados NoSQL são:

-Distribuído:

- Escalabilidade Horizontal

- Construído para grande volume de dados

- BASE ao invés de ACID

- Modelo de dados não relacional

- Sem definições de esquema

- Não suporta SQL

\cite{nasholm:2012}

\subsection{Banco de dados Orientados à Documentos}

Banco de dados orientados a documentos são capazes de armazenar documentos como dado. Esses documentos podem ser em qualquer formato como XML (eXtensible Markup Language), YAML (Yet Another Markup Language), JSON (JavaScript Object Notation), entre outros. Os documentos são agrupados na forma de coleções, comparando com banco de dados relacional as coleções são como tabelas e os documentos como os registros. Porém, a diferença entre eles é que cada registro na tabela do banco relacional tem o mesmo número de campos, enquanto que nos documentos na coleção do banco de dados orientado a documentos podem ter campos completamente diferentes (Kaur; Rani, 2013).

Existem mais de 15 banco de dados orientados a documentos disponíveis e os mais utilizados são MongoDB, CouchDB e o RavenDB (Kaur; Rani, 2013).

\subsection{Banco de dados Famílias de Colunas}

Banco de dados baseados em Famílias de Colunas são desenvolvidos para abranger três áreas: número enorme de colunas, a natureza esparsa dos dados e frequentes mudanças no esquema. Os dados em Famílias de colunas são armazenados em colunas de forma contínua, enquanto que em bancos de dados relacionais as linhas é que são contínuas. Essa mudança faz com que operações como agregação, suporte para ad-hoc e consultas dinâmicas se tornem mais eficientes (Kaur; Rani, 2013).

A maioria dos bancos de dados baseados em Famílias de Colunas são também compatíveis com o framework MapReduce, no qual acelera o processamento de enorme volume de dados pela distribuição do problema em um grande número de sistemas. Os bancos de dados  de Família de Colunas open-source mais populares são Hypertable, HBase e Cassandra (Kaur; Rani, 2013).

\subsection{Banco de dados Baseado em Grafos}

Bancos de dados baseado em Grafos são como uma estrutura de rede contendo nós e arestas, onde as arestas interligam os nós representando a relação entre eles. Comparando com o modelo Entidade-Relacionamento, o nó corresponde à entidade, a propriedade do nó à um atributo, a relação entre as entidades ao relacionamento entre os nós. Nos bancos de dados relacionais as consultas requerem atributos de mais de uma tabela resultando numa operação de junção, por outro lado, bancos de dados baseado em Grafos são desenvolvidos para encontrar relações dentro de uma enorme quantidade de dados rapidamente, tendo em vista que não é preciso fazer junções, ao invés disso, ele fornece indexação livre de adjacência (Kaur; Rani, 2013).

\subsection{Banco de dados Chave-Valor}

Em Bancos de dados Chave-Valor os dados são organizados como uma associação de vetores de entrada consistindo em pares de chave-valor. Cada chave é única e é usada para recuperar os valores associados a ele. Esses bancos de dados podem ser visualizados como um banco de dados relacional contendo múltiplas linhas e apenas duas colunas: chave e valor. Buscas baseadas em chaves resultam num baixo tempo de execução, além disso, os valores podem ser qualquer coisa como objetos, hashes, entre outros (Kaur; Rani, 2013).

Os bancos de dados Chave-Valor mais populares são Riak, Voldemort e Redis (Kaur; Rani, 2013).

\section{Projeto Conceitual, Lógico e Físico}

Tradicionalmente um projeto de banco de dados é modelado em três fases denominadas conceitual, lógica e física. O projeto conceitual consiste em apresentar um esquema expressivo que modele os dados de um determinado domínio de informação, enquanto que o projeto lógico transforma um esquema conceitual em algo que se aproxima de um modelo de implementação física do banco de dados. Em projetos de banco de dados NoSQL, há poucos trabalhos que abordam uma metodologia para esquemas lógicos baseados em modelagens conceituais (Lima; Mello, 2015). 
		 	 	 							
Dessa forma, esta seção visa aprofundar o tema a respeito de projeto conceitual e lógico em banco de dados NoSQL.

\subsection{Modelo Conceitual NoSQL}

Em bancos de dados relacionais, o modelo conceitual mais utilizado na literatura é o modelo ER (Entidade-Relacionamento) (Fowler, 2013). Contudo, bancos de dados NoSQL necessitam de um modelo conceitual que atenda às suas características. 

O desenvolvimento de banco de dados para sistemas NoSQL é usualmente baseado nas melhores práticas, nas quais são especificamente relacionadas ao sistema desenvolvido, com nenhuma metodologia sistematizada (Bugiotti; Cabibbo; Atzeni, 2014). Por isso, Bugiotti et al (2014) desenvolveu uma abordagem baseada no NoAM (NoSQL Abstract Model).  Esta abordagem observa que vários sistemas NoSQL compartilham de características de modelagem similares. Uma importante observação é que sistemas NoSQL oferecem operações de acesso aos dados de forma eficiente, atômica e escalável nas unidades de acesso aos dados em uma certa granularidade.  Uma representação errada pode levar a incapacidade de garantir a atomicidade das operações importantes e o desempenho pode piorar dependendo magnitude da aplicação. 

A metodologia de Bugiotti et al (2014) procede com a identificação dos agregados, onde cada agregado é um grupo de objetos relacionados que podem ser acessados e/ou manipulados juntos. Essa atividade é importante para suportar escalabilidade e consistência. O modelo conceitual desenvolvido por Bugiotti et al (2014) segue o modelo padrão do DDD (Domain-Driven Design), no qual é uma metodologia muito utilizada em orientação à objeto. Dessa forma, para o modelo conceitual NoSQL, é utilizado o diagrama de classe conceitual da UML, definindo as entidades, valores dos objetos e relacionamentos da aplicação.

\subsection{Modelo Lógico NoSQL}

O modelo de dados lógico dominante nas últimas décadas tem sido o modelo relacional (Fowler, 2013). Porém, para bancos de dados NoSQL a modelagem relacional não atende as características para representação lógica de seus dados. Para Fowler (2013), cada solução NoSQL possui um modelo diferente, os quais ele dividiu em quatro categorias amplamente usadas na literatura: chave-valor, documento, famílias de colunas e grafos.

Nesse mesmo contexto, Lima (2015) propôs a utilização de esquemas lógicos para NoSQL que utilizam o conceito de agregados. Ele justifica a escolha pelo fato de que a representação lógica baseada em agregados apoia os requisitos típicos dos bancos de dados NoSQL, oferecendo suporte à escalabilidade, consistência e desempenho. O conceito de agregados é um termo da área Domain-Driven Design (DDD), sendo uma coleção de objetos relacionados, aninhados, representando como uma única entidade (Lima;Mello, 2015). 

Agregado é um padrão de domínio usado para definir a propriedade e fronteira do objeto. Ele é um grupo de objetos associados que são considerados como uma unidade em relação a alterações de dados. O Agregado é demarcado pela fronteira que separa os objetos de dentro para fora. Cada Agregado tem uma raiz. A raíz é uma Entidade, e ela é o único objeto que é acessível de fora do agregado. A raíz pode guardar referências para qualquer dos objetos agregados, e os outros objetos podem guardar referências uns dos outros, mas um objeto de fora só pode guardar referências do objeto raíz. Se houver outras Entidades dentro da fronteira, a identidade dessas entidades é local, fazendo sentido somente dentro do agregado (Domain-Driven Design Quickly, 2006).

Fowler (2013), define um agregado como um conjunto de objetos relacionados que são tratados como uma unidade, mais precisamente, é uma unidade de manipulação de dados e gerenciamento de consistência. Ele afirma também que trabalhar com banco de dados orientados a agregados traz uma semântica mais clara, enfocando a unidade da interação com o armazenamento de dados. Contudo, o motivo mais importante para a utilização da modelagem orientada a agregados em bancos de dados NoSQL é que ela auxilia a execução em um cluster. Quando se opera em um cluster é necessário minimizar o número de nós a serem pesquisados na coleta de dados. Assim, ao incluir os agregados é possível dar a informação ao banco de dados sobre quais partes serão manipuladas juntas e no mesmo nó.

Dessa forma, a utilização de um modelo lógico NoSQL baseado em agregados se justifica pelo fato de que o conceito desse modelo possibilita o gerenciamento de consistência, a execução em cluster e uma semântica mais clara.

\section{Frameworks}

\section{Trabalhos Correlatos}
Esta seção aborda os trabalhos que são correlatos a esta pesquisa, bem como descreve como estes trabalhos diferem do realizado
por esta pesquisa.

\subsection{Experiência do Usuário}
Uma abordagem apresentado por Tableau permite em sua ferramenta que o usuário possa adicionar scripts Hive que consequentemente são executados em um Hadoop cluster. A saída é então importada para a memória no Tableau. O usuário define quais dados do sistema de arquivo devem ser processados, e o quanto complexo os dados deverão ser comprimidos para o formato que a aplicação suporte. Utilizando o cluster de várias máquinas esse processamento permite que o Tableau obtenha resposta rápida para um grande volume de dados até mesmo quando não há nenhum mecanismo de busca disponível. Obviamente, esta abordagem exige que o usuário tenha um conhecimento avançado, e também que haja uma análise a respeito da estrutura na qual os dados estão armazenados antes da importação.

\cite{nasholm:2012}

\subsection{Solução Spotfire}




% ---


%\lipsum[2-3]

\clearpage

% ----------------------------------------------------------
% PARTE
% ----------------------------------------------------------
%\part{Resultados}
% ----------------------------------------------------------

% ---
% primeiro capitulo de Resultados
% ---
\chapter{O Framework ETL4NoSQL}
% ---
Neste capítulo serão apresentados os conceitos do Framework ETL4NoSQL. Este consiste numa plataforma de software para desenvolvimento de sistemas ETL, cujo os dados de origem provêm de bases de dados não relacionais. Mais especificamente, bases de dados NoSQL que pertencem a um dos quatro paradigmas de NoSQL: Orientada a documentos, Família de Colunas, Chave-Valor e Baseada em Grafos.

O Framework oferece um ambiente integrado para modelar processos de ETL e implementar funcionalidades utilizando uma linguagem de programação independente de uma GUI (\emph{Graphical User Interface} - Interface Gráfica do Usuário).

Para a especificação do Framework foram definidas as estruturas dos dados dos ambientes de origem, destino e área de processamento de dados e suas respectivas linguagens de manipulação, e também, as principais funcionalidades dos sistemas de ETL, chamados mecanismos de ETL. Para realizar os processos de ETL foi definido um controlador de operações que é capaz de se comunicar com os ambientes e os mecanismos de ETL. 

Nas seções deste capítulo serão detalhados os requisitos, a arquitetura, os fluxos de dados e diagramas utilizados no desenvolvimento do Framework.
\clearpage
% ---
\section{Requisitos do ETL4NoSQL}


Para que seja possível a extração, transformação e carga dos dados armazenados em bancos de dados que utilizam um dos paradigmas de NoSQL é preciso que seja definido o esquema no qual os dados necessários estão armazenados. Dessa forma, algumas questões importantes são abordadas:

\begin{itemize}
\item Quanto os BDs NoSQL diferem dos BDs suportados pelas ferramentas de ETL?

\item Como é possível oferecer suporte para ETL em BDs NoSQL?
\end{itemize}

As diferenças dos BDs NoSQL já foram abordadas nos capítulos de fundamentação teórica. Assim, fica explícito o problema de como é possível converter os modelos de dados NoSQL em modelos relacionais que possam ser lidos por qualquer ferramenta de ETL. \cite{nasholm:2012}  define uma tabela como uma representação de uma coleção de instâncias de entidades comparáveis. Então, possibilitar suporte para armazenamentos de dados NoSQL é permitir extração e importação de instâncias de entidades comparáveis em tabelas relacionais. Porém, os problemas a serem resolvidos abordados por \cite{nasholm:2012} para atingir isso incluem:

\begin{enumerate}
\item Como permitir o usuário especificar as entidades comparáveis e seus atributos?

\item Como, e de onde, extrair exatamente?

\end{enumerate}
A solução sugerida pelo autor é um esquema ser deduzido por meio de uma amostra do banco de dados. Este esquema pode, então, ser apresentado ao usuário que procede selecionando quais atributos importar do que foi apresentado - exatamente como no caso do RDBMS. É claro que também deverá ser possível ao usuário editar os esquemas apresentados tendo em vista que a amostra pode não ser perfeita. Essa abordagem geral é referida como dedução de esquema - \textit{schema inference}.

Construir uma amostra com todo o banco de dados pode ser muito custoso, por isso é preferível que faça uma amostra com pequenas estruturas, como por exemplo, uma entidade inteira. É claro que muitas vezes não há esse tipo de estrutura, então é possível que a amostra seja colocada em clusters. Múltiplas entidades podem ser divididas cada uma em um cluster, e assim, é possível ter um esquema de entidade por cluster.

Dessa forma, dado o que extrair, consultar e recuperar dados de um RDBMS é direto por causa do SQL. Sistemas NoSQL geralmente tem diferentes interfaces que suportam diferentes tipos de consultas. Então, não há nenhuma sugestão de solução geral para isso. Ao invés disso, uma investigação de cada interface particular dos sistemas deve ser conduzida para resolver o problema \cite{nasholm:2012}. 

Para suprir o problema a respeito das várias interfaces a serem lidadas na extração de dados de bases NoSQL, foi sugerido criar um ambiente programável que oferecesse interfaces previamente selecionadas e permitisse a inserção de novas interfaces por meio de linguagem de programação. 

\subsection{Descrição Geral do Sistema}

O ETL4NoSQL consiste em um framework programável, flexível e integrado para modelagem e execução de processos ETL em BDs NoSQL. 

Separamos os requisitos em duas etapas, os requisitos para as funcionalidades de ETL e os requisitos para a usabilidade de BDs NoSQL. Baseado nesses requisitos foi possível identificar os padrões de análise do framework, e assim, definir sua arquitetura.

\section{Padrões de Análise de NoSQL}

Segundo a pesquisa de Nasholm (2012), os requisitos necessários para lidar com dados que são armazenados em banco de dados não relacionais devem suportar buscas sob demanda. Devido à característica de bancos de dados NoSQL lidarem com um grande volume de dados é importante que as buscas sejam feitas conforme a necessidade desses dados. Dessa forma, os requisitos para BDs NoSQL são baseados nessa premissa, os padrões definidos pelos requisitos levantados foram os padrões de importação e padrões de mapeamento.

\subsection{Padrões de importação}

Padrões de importação são requisitos para possibilitar a importação dos dados de bases NoSQL, e assim, permitir a execução de processos ETL.

\subsubsection{Definição de ambiente e estrutura de dados}

\begin{itemize}

	\item[a)] Contexto: É preciso definir quais as estruturas da base de dados NoSQL a ser importada, bem como a linguagem de manipulação dos dados da base para que seja possível a importação.
	
	\item[b)] Problema: É necessário oferecer a linguagem de manipulação da base de dados a ser importada, os tipos de dados que serão utilizados e local onde os dados se encontram.
	
	\item[c)] Estrutura: Define as configurações de importação, oferecendo a informação de onde o dado é localizado, que dados incluir no resultado, como importá-lo e outras fontes de parâmetros específicos.
	
	\item[d)] Participantes: Apresenta os elementos para a importação.
	
	\begin{itemize}
		\item Ambiente: fonte de onde o dado é localizado.
		
		\item Consulta: define quais dados serão necessários.
		
		\item Repositório: Define os atributos do repositório de dados, bem como a forma de conexão com o ambiente, forma de manipulação dos dados e outras configurações que permitam a leitura e escrita.
		
		\item Amostra: Define quais colunas e tipos de dados que serão utilizados para cada ambiente.
		
	\end{itemize}
	
	\item[e)] Próximos padrões: Concluindo as definições de ambiente e estrutura de dados, a próxima etapa é estipular os mecanismos de importação.
	
\end{itemize}

\subsubsection{Mecanismos de importação}


\begin{itemize}

	\item[a)] Contexto: É necessário definir mecanismos para a importação dos dados da base NoSQL de origem para permitir o uso desses dados em ferramentas de ETL.
	
	\item[b)] Problema: É preciso determinar quais mecanismos são fundamentais para a importação dos dados.
	
	\item[c)] Estrutura: O mecanismo pode ser definido como busca Sob Demanda ou busca Exaustivo. Mecanismo de busca Sob Demanda significa que o dado da fonte de dados só é buscado quando explicitamente demandado, e que não é buscado nenhum outro dado que não foi demandado. O mecanismo de busca Sob Demanda é muito importante quando se trata de análises em Big Data, pois as análises podem ser conduzidas de cima para baixo onde o usuário começa com uma visão agregada de um conjunto de dados e pode explorar detalhes se desejado. A visão inicial do agregado pode originar vários processos de ETL (Nasholm, 2012). Mecanismo de busca Exaustiva a busca é feita em uma única vez. O único requisito necessário é a configuração de importação.
	
	\item[d)] Participantes:
	
	\begin{table*}[ht]
  		\centering
  		\caption{Mecanismos básicos para Importação}
  		\begin{tabular}{|p{6cm}| p{6cm} |}
    			\hline
    			Fase de Importação & Mecanismo Padrão\\
			\hline
			Definição da estrutura de dados & Conexão ao Banco de dados\\
			& Definição da linguagem de manipulação de dados\\
    			\hline
    			Busca & Sob Demanda\\
			& Exaustiva\\
    			\hline
  		\end{tabular}
	\end{table*}

	
	\item[e)] Próximos padrões: Após a definição dos mecanismos de importação, o próximo passo é executar o mapeamento para a estrutura que será utilizada pelos processos de ETL.
	

\end{itemize}


\subsection{Padrões de Mapeamento}

Padrões de mapeamento são requisitos para executar o mapeamento dos dados importados das bases NoSQL, modelando-os de forma que possibilite a leitura e execução dos processos de ETL.

\subsubsection{Execução do processo de mapeamento}

\begin{itemize}

	\item[a)] Contexto: Para cada paradigma NoSQL, é necessário definir regras de mapeamento que transforme o modelo não relacional em uma estrutura que mapeie as relações permitindo a leitura e execução de processos de ETL.
	
	\item[b)] Problema: Deve-se identificar a estrutura da base de dados importada e possibilitar o mapeamento dessa base para um esquema que permita a leitura e execução de processos de ETL.
	
	\item[c)] Estrutura: O mapeamento é definido de acordo com os quatro paradigmas NoSQL: chave-valor, família de colunas, orientado a documentos e baseado em grafos.
		
	\item[d)] Participantes:
	
	\begin{table*}[ht]
  		\centering
  		\caption{Regras de Mapeamento}
  		\begin{tabular}{|p{6cm}| p{6cm} |}
    			\hline
    			Paradigma NoSQL & Regras\\
			\hline
			Chave-Valor & Um campo chave pode ser mapeada como tabela relacional\\
			& Uma coluna da chave correspondente pode ser mapeada como coluna da tabela da chave\\
			& O valor correspondente de uma coluna é mapeada como linha da tabela\\
    			\hline
    			Família de Colunas & Uma família pode ser mapeada como tabela\\
			& Uma coluna da família de colunas pode ser mapeada para uma coluna da tabela\\
    			\hline
			Orientado a Documentos & Um documento corresponde a uma linha da tabela\\
			& Cada campo do documento pode ser coluna da tabela relacional\\
			\hline
			Baseado em Grafos & O vértice ou aresta pode ser mapeado para uma tabela relacional\\
			& Cada atributo do vértice ou aresta pode ser mapeado para colunas\\
			\hline
  		\end{tabular}
	\end{table*}

	
	\item[e)] Próximos padrões: Com as regras de mapeamento definidas, o passo seguinte é definir metadados e os mecanismos de ETL padrões para os processos de ETL.
	

\end{itemize}



\subsection{Padrões de Análise de ETL}

Segundo Silva (2012), não há um consenso a respeito das funcionalidades básicas dos sistemas de ETL, porém é possível definir, baseado nos conceitos disponíveis na literatura, requisitos de operações e metadados. 

Requisitos de metadados definem as estruturas que cada processo de ETL necessita, onde podem ser consideramos pontos de flexibilidade. Já os requisitos de operações não mudam para qualquer processo de ETL, sendo assim, pontos de estabilidade.

Os principais requisitos de metadados e operações baseadas nas definições de Silva (2012) e consideradas fundamentais para o desenvolvimento do framework deste trabalho são descritas a seguir.

\subsection{Padrões de Metadados}

Padrões de metadados são requisitos de preparação do ambiente e definição de variáveis para a execução de operações de ETL.

\subsubsection{Definição dos ambientes e das estruturas de dados}

Este padrão consiste na preparação para a execução de processos de ETL.


\begin{itemize}
\item[a)] Contexto: É necessário ao menos três ambientes para a execução de processos de ETL: fonte, área de processamento e destino.

\item[b)] Problema: É preciso definir que tipo de ambiente e estrutura de dados estarão disponíveis e permitirão acesso pelo framework.

\item[c)] Estrutura: Expõe sugestões para resolver o problema de definição dos ambientes, de acordo com cada requisito da estrutura dos dados. As definições de ambiente do framework proposto, para a parte de ETL, define a estrutura para os principais repositórios não relacionais e relacionais na literatura.

\item[d)] Participantes: Apresenta os elementos do ambiente e estrutura de dados.

	\begin{enumerate}
		\item Ambiente: Define se o ambiente é fonte, destino ou área de processamento.
		
		\item Repositório de dados: Define os atributos do repositório de dados, bem como a forma de conexão com o ambiente, forma de manipulação dos dados e outras configurações que permitam a leitura e escrita.
		
		\item Esquema de dados: Define as tabelas, campos, relacionamentos, visões, índices, pacotes, procedimentos, funções, filas, gatilhos, tipos, sequências, visões materializadas, sinônimos, enlaces de banco de dados, diretórios, esquemas XML e outros elementos dos ambientes.
		
		\item Amostra: Define quais colunas e tipos de dados que serão utilizados para cada ambiente. 
		
	\end{enumerate}

	\begin{figure}[h!]
		\centering
		\caption{Diagrama de Classe da Definição dos Ambientes e Estrutura de dados}
		\includegraphics[scale=0.5]{Diagrama_classe_repositorio.png}
		\label{arquitetura}
	\end{figure}
	
	\item[e)] Próximos padrões: Após as definições de ambientes e estrutura de dados, o passo seguinte é definir os mecanismos padrões para o ETL.

\end{itemize}

\subsubsection{Mecanismos de ETL}

\begin{itemize}

\item[a)] Contexto: É necessário definir mecanismos básicos para a execução de processos de ETL. Os mecanismos mais comuns encontrados na literatura (Silva, 2012) estão expostos na tabela 3.1.

\begin{table*}[ht]
  \centering
  \caption{Mecanismos básicos para o padrão de análise Mecanismos de ETL}
  \begin{tabular}{|p{6cm}| p{6cm} |}
    \hline
    Fase de ETL & Mecanismo Padrão\\
    \hline
    Extração & Extrair dados\\
    \hline
    Transformação & Filtrar dados\\
     & Unir dados\\
    & Agregar dados\\
    & Juntar dados\\
    & Gerar Chaves\\
    & Pesquisar chaves\\
    & Converter dados\\
    \hline
    Carga & Carregar dados\\
    \hline
  \end{tabular}
\end{table*}

\item[b)] Problema: É necessário determinar quais os mecanismos fundamentais para o funcionamento dos recursos padrões de ETL. Dessa forma, determinar quais processos deverão estar disponíveis, e como utilizá-los.

\item[c)] Estrutura: Define os mecanismos padrões utilizados pelos processos de ETL. Porém, esse conjunto de mecanismos pode não atender a necessidade de todas as aplicações, é necessário permitir a criação de mecanismos personalizados para um determinado domínio de aplicação. Além disso, deve ser possível personalizar e reutilizar os mecanismos existentes.

\item[d)] Participantes: Apresenta os elementos dos mecanismos comuns e personalizados.
	
	\begin{enumerate}
		\item Fila: conjunto de processos de um mecanismo em ordem de execução.
		
		\item Processo: área de processamento, origem do processo, atributos do processo.
		
		\item Mecanismo Padrão: mecanismos básicos mais relevantes para a execução de processos de ETL.
		
		\item Mecanismo Personalizado: mecanismos personalizados para atender domínios específicos.
		
		\item Personalizador de mecanismo: tem a função de permitir ao programador alterar comportamentos dos mecanismos padrões.
		
		\begin{figure}[h!]
		\centering
		\caption{Diagrama de Classe Mecanismos de ETL}
		\includegraphics[scale=0.5]{Metadados_mecanismo.png}
		\label{meanismo}
	\end{figure}
		
		
	\end{enumerate}
\item[e)] Próximos padrões: O passo seguinte à modelagem dos mecanismos padrões de ETL é a definição dos padrões de operação.

\end{itemize}

\subsection{Padrões de Operação}

Padrões de Operação são requisitos para a execução dos processos de ETL.

\subsubsection{Leitura dos ambientes e das estrutura de dados}

\begin{itemize}

	\item[a)] Contexto: É preciso executar a leitura dos ambientes e de estrutura de dados que farão parte dos processos de ETL. Para a execução dos mecanismos padrões é necessário que haja a definição e posteriormente a leitura dos dados.
	
	\item[b)] Problema: A leitura dos dados deve ser feita de forma que possibilite a execução dos processos de ETL por meio dos mecanismos padrões ou personalizados.

	\item[c)] Estrutura: A operação de leitura é feita por meio da instanciação dos elementos:
	
		\begin{enumerate}
			\item Ambiente: determina o método de criação do ambiente, bem como a instanciação dos seus atributos.
			
			\item Repositório de dados: determina o método de criação de repositório de dados, onde é possível definir quais tipos de dados estão presente no determinado ambiente.
			
			\item Esquema de dados: determina o método de leitura do esquema dos dados do ambiente, essa leitura é feita por meio da linguagem de manipulação de dados.
			
			\item Amostra: determina a leitura das colunas e tipos de dados de um determinado esquema de dados.
			
			\begin{figure}[h!]
				\centering
				\caption{Fluxograma da criação de Ambientes}
				\includegraphics[scale=0.5]{fluxo_leitura_ambiente.png}
				\label{fluxograma}
			\end{figure}
			
			
		\end{enumerate}
		
	\item[d)] Participantes: apresentação os principais métodos para leitura dos ambientes e estrutura de dados.
	
	\begin{table*}[h!]
  		\centering
  		\caption{Métodos de Leitura de Metadados}
  		\begin{tabular}{| p{4cm} | p{4cm} |}
    		\hline
    		Descrição & Método\\
    		\hline
		Conexão ao Banco de dados& connectDB\\
		\hline
		Criação de Esquema de dados & createSchema\\
		\hline
		Armazena os dados & setData\\
		\hline
		Consulta os dados & getData\\
		\hline
		Criação de Amostra & createSample\\
		\hline

  		\end{tabular}
	\end{table*}

	
	\item[e)] Próximos padrões: a próxima etapa a ser definida é o padrão da execução dos processos de ETL.
	
\end{itemize}

\subsubsection{Execução dos processos de ETL}

\begin{itemize}

	\item[a)] Contexto: Por meio da definição dos mecanismos básicos dos processos de ETL é possível realizar a sua execução. 
	
	\item[b)] Problema: A execução dos processos deverá ser feita de acordo com a seu grau de prioridade definida pelo usuário.
	
	\item[c)] Estrutura: A execução dos processos é feita por meio da definição do seu mecanismo.
	
	\item[d)] Participantes: Mecanismos dos processos de ETL.	
	
	\item[e)] Próximos padrões: Após a execução dos processos de ETL, o passo seguinte é a definição dos padrões de análise de NoSQL para permitir o uso de banco de dados do paradigma NoSQL pelo framework.
	

\end{itemize}

\begin{table}[ht]
  \centering
  \caption{Padrões de Análise do ETL4NoSQL}
  \begin{tabular}{| p{4cm} | p{2cm} | p{6cm} |}
    \hline
    Subsistema & Padrão de Análise & Etapa\\
    \hline
    ETL & Metadados & - Definição de Ambiente e Estrutura de dados\\
     && - Mecanismos de ETL\\
    \hline
    ETL & Operação & - Leitura de Ambiente e Estrutura de dados\\
     && - Execução dos mecanismos de ETL\\
    \hline
    NoSQL & Importação & - Definição de Ambiente e Estrutura de dados\\
     &  & Mecanismos de NoSQL\\
    \hline
    NoSQL & Mapeamento & - Leitura de Ambiente e Estrutura de dados\\
     & & - Execução dos mecanismos NoSQL\\
    \hline
  \end{tabular}
\label{tab:padraoanalise}
\end{table}

Com isso, por meio das definições de requisitos foi possível definir os padrões de análise que estão apresentados na tabela \ref{tab:padraoanalise}.

%\subsection{Processos de ETL}
%colocar aqui a respeitos dos processos de etl mais comum nas ferramentas de etl.

%\subsection{Projeto de Sistemas Baseado em Componentes}

%\subsubsection{Modelagem de Domínio}
%Definir casos de uso : especificam funcionalidades existentes no sistema
%Definir modelo conceitual : especificam as entidades do mundo real manipuladas pelo sistema
%Definir modelo comportamental : identificar estados, transições de estados e eventos

%\subsubsection{Especificação do Software}
%Identificar componentes: Produz uma especificação de arquitetura inicial
%de um sistema, Identifica as interfaces suportadas por cada
%componente, Deve-se sempre buscar reutilizar componentes 


%Identificar interações entre componentes: Identifica as operações necessárias, Atribui responsabilidades


%Especificar componentes: Cria uma especificação detalhada das interfaces
%dos componentes, definindo as assinaturas de
%suas operações e suas propriedades




\section{Arquitetura do ETL4NoSQL}

A arquitetura do Framework será apresentada nesta seção, ela foi definida baseada em componentes. Segundo \cite{sametinger:1997}, componentes são uma parte do sistema de software que podem ser identificados e reutilizados, onde descrevem ou executam funções específicas e possuem interfaces claras, documentação apropriada e a possibilidade de reuso bem definida. Ainda de acordo com o autor, um componente deve ser autocontido, identificável, funcional, possuir uma interface, ser documentado e ter uma condição de reuso. Dessa forma, definimos os componentes do ETL4NoSQL de acordo com essas características e serão apresentados na seção 3.3.1.

\subsection{Componentes do ETL4NoSQL}

A seguir são apresentados os modelos de componentes do Framework ETL4NoSQL de acordo com os padrões de análise e as convenções estabelecidas por \cite{heineman:2001}.


\begin{figure}[h!]
\centering
\includegraphics[scale=0.5]{diagrama_componentes.png}
\caption{Arquitetura do Framework baseada em Componentes}
\label{arquitetura}
\end{figure}


 
 \subsubsection{Componente de Importação}
 
 \begin{itemize}
	\item[a)] Interface: Componente responsável pela importação dos dados da base de origem
	
	\item[b)] Nomeação: Componente de Importação
	
	\item[c)] Metadados: Este componente será composto com as informações da base de origem e da busca dos dados, apresentará uma interface para o usuário disponibilizar as informações e fornecerá os dados para o componente de mapeamento.
	
	\item[d)] Interoperabilidade: Deve possibilitar a comunicação entre outros componentes 
	
	\item[e)] Composição: 
	
		\begin{table*}[h!]
  			\centering
 			 \caption{Métodos do Componente Importação}
  			\begin{tabular}{| p{4cm} | p{6cm} | p{6cm} |}
    			\hline
    			Método & Descrição & Comportamento\\
    			\hline
    			ConnImportDB & Conecta com o banco de dados onde os dados serão importados & Estabelece a conexão com a base de dados de importação\\
    			\hline
    			setDMLImportDB & Define a linguagem de manipulação de dados da base de importação & Armazena os parâmetros de manipulação de dados da base de dados de importação\\
    			\hline
    			queryImportDB & Define a consulta de onde os dados serão importados & Retorna os dados que serão importados mantendo suas relações, a importação pode ser Sob Demanda ou Exaustiva\\
    			\hline
    			getDMLImportDB & Retorna a configurações da linguagem de manipulação de dados da base de importação que foram estabelecidas & Retorna as configurações da DML da base de importação\\
    			\hline
  			\end{tabular}
			\label{tab:metodosimportacao}
		\end{table*}

	
	\item[f)] Customização: Este componente pode ser customizado em sua interface com o usuário, possibilitando outras meios de fornecer as informações para os seus métodos
	
	\item[g)] Suporte a evolução: Deve possibilitar o suporte aos métodos de acordo com as mudanças de conexões e manipulações de bases de dados futuras
	
	\item[h)] Empacotamento e utilização: Os métodos deverão ser encapsulados e poderão ser utilizados pela importação de sua classe e a interface com o usuário será por meio de linha de comando

 \end{itemize}
 
 \subsubsection{Componente de Mapeamento}
 
  \begin{itemize}
	\item[a)] Interface: Componente responsável por gerar o mapeamento dos dados oferecidos pelo componente de importação para um esquema relacional
	
	\item[b)] Nomeação: Componente de Mapeamento
	
	\item[c)] Metadados: Este componente deverá estabelecer comunicação com o componente de importação, apresentará uma interface para o usuário definir a regra a ser utilizada no mapeamento e fornecerá os dados para o componente de leitura e escrita de metadados
	
	\item[d)] Interoperabilidade: Deve possibilitar a comunicação entre outros componentes
	
	\item[e)] Composição:
	
	\begin{table*}[h!]
  			\centering
 			 \caption{Métodos do Componente Mapeamento}
  			\begin{tabular}{| p{4cm} | p{6cm} | p{6cm} |}
    			\hline
    			Método & Descrição & Comportamento\\
    			\hline
    			getImportData & Busca os dados do componente de importação & Estabelece a comunicação com o componente de importação\\
    			\hline
    			setMapRules & Define as regras de mapeamento & Define um conjunto de regras de mapeamento para um esquema relacional\\
    			\hline
    			getMapRules & Retorna uma regra de mapeamento & Retorna uma regra de mapeamento do conjuntos de regras\\
    			\hline
    			runMap & Gera o mapeamento de acordo com a regra estabelecida & Retorna os dados no esquema relacional de acordo com a regra de mapeamento escolhida\\
    			\hline
  			\end{tabular}
			\label{tab:metodosmapeamento}
		\end{table*}
	
	\item[f)] Customização: É possível customizar as regras de mapeamento para outros esquemas não relacionais
	
	\item[g)] Suporte a evolução: Deve possibilitar o suporte aos métodos de acordo com a necessidade de alterar os esquemas dos dados
	
	\item[h)] Empacotamento e utilização: Os métodos deverão ser encapsulados e poderão ser utilizados pela importação de sua classe e a interface com o usuário será por meio de linha de comando

 \end{itemize}
 
  \subsubsection{Componente de Leitura e Escrita de Metadados}
 
  \begin{itemize}
	\item[a)] Interface: Componente responsável pela criação de ambientes para a execução de processos de ETL
	
	\item[b)] Nomeação: Componente de Leitura e Escrita de Metadados
	
	\item[c)] Metadados: Este componente deverá estabelecer comunicação com o componente de importação caso o ambiente seja fonte de dados, deve criar um esquema para o ambiente de processamento de dados, um esquema para o ambiente de destino e uma amostra para os dados importados
	
	\item[d)] Interoperabilidade: Deve possibilitar a comunicação entre outros componentes
	
	\item[e)] Composição: 
	
	\begin{table*}[h!]
  			\centering
 			 \caption{Métodos do Componente de Leitura e Escrita de Metadados}
  			\begin{tabular}{| p{4cm} | p{6cm} | p{6cm} |}
    			\hline
    			Método & Descrição & Comportamento\\
    			\hline
    			connectDB & Estabelece conexão com o banco de dados do ambiente & Permite a conexão com as bases de dados fonte, destino e área de processamento de dados\\
    			\hline
    			createSchema & Cria a esquema de dados do ambiente & Permite a criação de um esquema relacional para cada tipo de ambiente\\
    			\hline
    			setData & Armazena os dados num determinado ambiente & Permite armazenar os dados de um determinado ambiente\\
    			\hline
    			getDataMap & Estabelece a comunicação com os dados mapeados & Retorna os dados que foram mapeados pelo componente de mapeamento\\
    			\hline
			createSample & Cria uma amostra dos dados mapeados pelo componente de mapeamento & Retorna os dados da amostra\\
			\hline
  			\end{tabular}
			\label{tab:metodometadados}
		\end{table*}
	
	\item[f)] Customização: É possível customizar os ambientes de acordo com a necessidade do usuário
	
	\item[g)] Suporte a evolução: Deve possibilitar o suporte aos métodos de acordo com a necessidade de alterar os esquemas dos dados
	
	\item[h)] Empacotamento e utilização: Os métodos deverão ser encapsulados e poderão ser utilizados pela importação de sua classe e a interface com o usuário será por meio de linha de comando

 \end{itemize}
 
   \subsubsection{Componente de Mecanismos de ETL}
 
  \begin{itemize}
	\item[a)] Interface: Componente responsável por estabelecer os mecanismos que estarão disponíveis para a execução de processos de ETL
	
	\item[b)] Nomeação: Componente Mecanismos de ETL
	
	\item[c)] Metadados: Este componente deverá estabelecer comunicação com o componente de Leitura e Escrita de Metadados, apresentará uma interface para o usuário definir quais mecanismos a serem utilizados, bem como manterá os mecanismos que estarão disponíveis para o uso
	
	\item[d)] Interoperabilidade: Deve possibilitar a comunicação entre outros componentes
	
	\item[e)] Composição:
	
	\begin{table*}[h!]
  			\centering
 			 \caption{Métodos do Componente Mecanismos de ETL}
  			\begin{tabular}{| p{4cm} | p{6cm} | p{6cm} |}
    			\hline
    			Método & Descrição & Comportamento\\
    			\hline
    			mechanismType & Define o tipo de mecanismo & Estabelece a descrição de um mecanismo\\
    			\hline
    			mechanismPhase & Define a fase a qual o mecanismo pertence & Estabelece a descrição da fase a qual o mecanismo pertence\\
    			\hline
    			setParams & Determina os parâmetros utilizados pelo mecanismo & Estabelece conexão com o componente de metadados e define os parâmetros que serão executados pelo mecanismo \\
    			\hline
    			exec & Executa o mecanismo & Executa o comportamento do mecanismo de acordo com o parâmetros estabelecidos\\
    			\hline
			outPutSchema & Retorna o esquema criado pela a execução do mecanismo &Retorna o esquema resultado da execução do mecanismo\\
			\hline
  			\end{tabular}
			\label{tab:metodometadados}
		\end{table*}

	
	\item[f)] Customização: É possível customizar e criar mecanismos de acordo com a necessidade de cada processo de ETL
	
	\item[g)] Suporte a evolução: Deve possibilitar o suporte aos métodos de acordo com a necessidade de alterar os esquemas dos dados
	
	\item[h)] Empacotamento e utilização: Os métodos deverão ser encapsulados e poderão ser utilizados pela importação de sua classe e a interface com o usuário será por meio de linha de comando

 \end{itemize}
 
    \subsubsection{Componente de Operações}
 
  \begin{itemize}
	\item[a)] Interface: Componente responsável por criar e executar processos de ETL
	
	\item[b)] Nomeação: Componente de Operação
	
	\item[c)] Metadados: Este componente deverá possibilitar a comunicação com o componente de metadados e o componente de mecanismos de ETL e deverá criar e executar processos de ETL
	
	\item[d)] Interoperabilidade: Deve possibilitar a comunicação entre outros componentes
	
	\item[e)] Composição:
	
	\begin{table*}[h!]
  			\centering
 			 \caption{Métodos do Componente Operações}
  			\begin{tabular}{| p{4cm} | p{6cm} | p{6cm} |}
    			\hline
    			Método & Descrição & Comportamento\\
    			\hline
    			createProcess & Cria um processo de ETL & Estabelece comunicação entre o componente de metadados e o componente de mecanismos de ETL\\
    			\hline
    			createEnviroment & Cria um ambiente para executar o processo de ETL & Cria um ambiente fonte, APD ou Destino \\
    			\hline
    			execMechanism & Executa um mecanismo & Executa um mecanismo do componente mecanismos de ETL de acordo com os parâmetros estabelecidos \\
    			\hline
    			execProcess & Executa o processo de ETL criado & Retorna o resultado do processo de ETL\\
    			\hline
			loadDB & Carrega o resultado do processo de ETL para um ambiente destino & Armazena os dados do resultado do processo no banco de dados destino\\
			\hline
  			\end{tabular}
			\label{tab:metodooperacoes}
		\end{table*}
	
	\item[f)] Customização: É possível customizar os processos de ETL criados
	
	\item[g)] Suporte a evolução: Deve possibilitar o suporte aos métodos de acordo com a necessidade de alterar os processos
	
	\item[h)] Empacotamento e utilização: Os métodos deverão ser encapsulados e poderão ser utilizados pela importação de sua classe e a interface com o usuário será por meio de linha de comando

 \end{itemize}

\subsection{Implementação dos componentes do ETL4NoSQL}


\section{Considerações finais}
% ---

%\lipsum[21-22]

% ---
% segundo capitulo de Resultados
% ---
\chapter{Estudo de Caso}

Para a aplicação da representação da modelagem do processo de ETL observar Trujillo and Mora (2003) e Lujan-Mora and Trujillo (2003) referenciado na dissertação de Mario.
\clearpage

% ---
\section{Descrição}
\section{Considerações Finais}

% ---

%\lipsum[24]


% ---
% Conclusão
% ---
\chapter{Conclusão}
\clearpage

\section{Principais Contribuições}
\section{Discussão}
\section{Resultados}
\section{Trabalhos Futuros}
% ---

%\lipsum[31-33]



%%
%% Parte pós-textual
%%
\backmatter

% Apêndices
% Comente se não houver apêndices
\appendix

% É aconselhável criar cada apêndice em um arquivo à parte, digamos
% "apendice1.tex", "apendice.tex", ... "apendiceM.tex" e depois
% incluí-los com:
% \include{apendice1}
% \include{apendice2}
% ...
% \include{apendiceM}


% Bibliografia
% É aconselhável utilizar o BibTeX a partir de um arquivo, digamos "biblio.bib".
% Para ajuda na criação do arquivo .bib e utilização do BibTeX, recorra ao
% BibTeXpress em www.cin.ufpe.br/~paguso/bibtexpress
%\nocite{*}
\bibliographystyle{alpha}
\bibliography{minha_dissertacao_ufpe}

% Cólofon
% Inclui uma pequena nota com referência à UFPEThesis
% Comente para omitir
%\colophon

%% Fim do documento
\end{document}