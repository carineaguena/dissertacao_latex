%% Template para dissertação/tese na classe UFPEthesis
%% versão 0.9.2
%% (c) 2005 Paulo G. S. Fonseca
%% www.cin.ufpe.br/~paguso/ufpethesis

%% Carrega a classe ufpethesis
%% Opções: * Idiomas
%%           pt   - português (padrão)
%%           en   - inglês
%%         * Tipo do Texto
%%           bsc  - para monografias de graduação
%%           msc  - para dissertações de mestrado (padrão)
%%           qual - exame de qualificação doutorado
%%           prop - proposta de tese doutorado
%%           phd  - para teses de doutorado
%%         * Mídia
%%           scr  - para versão eletrônica (PDF) / consulte o guia do usuario
%%         * Estilo
%%           classic - estilo original à la TAOCP (deprecated)
%%           std     - novo estilo à la CUP (padrão)
%%         * Paginação
%%           oneside - para impressão em face única
%%           twoside - para impressão em frente e verso (padrão)
\documentclass{ufpethesis}

%% Preâmbulo:
%% coloque aqui o seu preâmbulo LaTeX, i.e., declaração de pacotes,
%% (re)definições de macros, medidas, etc.

%% Identificação:

% Universidade
% e.g. \university{Universidade de Campinas}
% Na UFPE, comente a linha a seguir
%\university{<NOME DA UNIVERSIDADE>}

% Endereço (cidade)
% e.g. \address{Campinas}
% Na UFPE, comente a linha a seguir
%\address{<CIDADE DA IES>}

% Instituto ou Centro Acadêmico
% e.g. \institute{Centro de Ciências Exatas e da Natureza}
% Comente se não se aplicar
\institute{Cin - Centro de Informática}

% Departamento acadêmico
% e.g. \department{Departamento de Informática}
% Comente se não se aplicar
%\department{<NOME DO DEPARTAMENTO>}

% Programa de pós-graduação
% e.g. \program{Pós-graduação em Ciência da Computação}
\program{Pós graduação em Ciência da Computação}

% Área de titulação
% e.g. \majorfield{Ciência da Computação}
\majorfield{Ciência da Computação}

% Título da dissertação/tese
% e.g. \title{Sobre a conjectura $P=NP$}
\title{ETL4NoSQL: Um framework de ETL para BDs NoSQL}

% Data da defesa
% e.g. \date{19 de fevereiro de 2003}
\date{<DATA DA DEFESA>}

% Autor
% e.g. \author{José da Silva}
\author{Carine Calixto Aguena}

% Orientador(a)
% Opção: [f] - para orientador do sexo feminino
% e.g. \adviser[f]{Profa. Dra. Maria Santos}
\adviser{Valéria Cesário Times}

% Orientador(a)
% Opção: [f] - para orientador do sexo feminino
% e.g. \coadviser{Prof. Dr. Pedro Pedreira}
% Comente se não se aplicar
%\coadviser{NOME DO(DA) CO-ORIENTADOR(A)}

%% Inicio do documento
\begin{document}

\renewcommand{\tablename}{Quadro}
\renewcommand{\listtablename{Lista de Quadros}}
%%
%% Parte pré-textual
%%
\frontmatter

% Folha de rosto
% Comente para ocultar
\frontpage

% Portada (apresentação)
% Comente para ocultar
\presentationpage

% Dedicatória
% Comente para ocultar
\begin{dedicatory}
<DIGITE A DEDICATÒRIA AQUI>
\end{dedicatory}

% Agradecimentos
% Se preferir, crie um arquivo à parte e o inclua via \include{}
\acknowledgements
<DIGITE OS AGRADECIMENTOS AQUI>

% Epígrafe
% Comente para ocultar
% e.g.
%  \begin{epigraph}[Tarde, 1919]{Olavo Bilac}
%  Última flor do Lácio, inculta e bela,\\
%  És, a um tempo, esplendor e sepultura;\\
%  Ouro nativo, que, na ganga impura,\\
%  A bruta mina entre os cascalhos vela.
%  \end{epigraph}
\begin{epigraph}[<NOTA>]{<AUTOR>}
<DIGITE AQUI A CITAÇÂO>
\end{epigraph}

% Resumo em Português
% Se preferir, crie um arquivo à parte e o inclua via \include{}
\resumo
<DIGITE O RESUMO AQUI>
% Palavras-chave do resumo em Português
\begin{keywords}
<DIGITE AS PALAVRAS-CHAVE AQUI>
\end{keywords}

% Resumo em Inglês
% Se preferir, crie um arquivo à parte e o inclua via \include{}
\abstract
% Palavras-chave do resumo em Inglês
\begin{keywords}
<DIGITE AS PALAVRAS-CHAVE AQUI>
\end{keywords}

% Sumário
% Comente para ocultar
%\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents

% Lista de figuras
% Comente para ocultar
\listoffigures

% Lista de tabelas
% Comente para ocultar
\listoftables


%%
%% Parte textual
%%
\mainmatter

% É aconselhável criar cada capítulo em um arquivo à parte, digamos
% "capitulo1.tex", "capitulo2.tex", ... "capituloN.tex" e depois
% incluí-los com:
% \include{capitulo1}
% \include{capitulo2}
% ...
% \include{capituloN}

 \pagestyle{fancy}
 \fancyhead[RE,RO]{\thepage}
\fancyhead[LE,LO]{\leftmark}
\fancyfoot[RE,RO]{C. C. Aguena}
\fancyfoot[LE,LO]{ETL4NoSQL: Um Framework de ETL para BDs NoSQL}
\fancyfoot[CE,CO]{}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{1pt}


\chapter{Introdução}
\noindent Este capítulo contextualiza os principais assuntos abordados neste trabalho de dissertação, apresenta as motivações que levaram à escolha do tema, os objetivos gerais e específicos da proposta desta pesquisa, bem como a justificativa para conduzir uma investigação no assunto debatido.
\clearpage

% ----------------------------------------------------------
% seção
% ----------------------------------------------------------

\section{Contextualização}
% ----------------------------------------------------------

Desde a década de 1970, com a criação do modelo relacional por Edgar Frank Codd, a estrutura de armazenamento adotada por muitos desenvolvedores de sistemas da área de tecnologia da informação tem se baseado no conceito de entidade e relação proposto por Codd. A maioria dos sistemas gerenciadores de banco de dados que possui aceitação no mercado fazem uso desse modelo, por exemplo o MySQL, Oracle e Microsoft SQL Server. Porém, os requisitos para o desenvolvimento de ferramentas de software modernas têm mudado significativamente, especialmente com o aumento das aplicações Web \cite{nasholm:2012}. Este segmento de aplicações exige requisitos com alta escalabilidade e vazão, onde sistemas que utilizam um armazenamento com esquema relacional não conseguem atender satisfatoriamente. Em resposta a isso, novas abordagens de armazenamentos de dados utilizando o termo de NoSQL tornaram-se popular.

O termo NoSQL é constantemente interpretado como  ''\emph{Not Only SQL}'', cujo SQL refere-se a linguagem de manipulação de dados dos gerenciadores de armazenamento de dados relacionais (RDBMS - Relational Database Management System) - Structure Query Language \cite{nasholm:2012}. O grande propósito das abordagens NoSQL é oferecer alternativas onde os esquemas relacionais não apresentam um bom desempenho. Esse termo abrange diferentes tipos de sistemas. Em geral, banco de dados NoSQL usam modelo de dados não-relacionais, com poucas definições de esquema, são executados em clusters e aplicados a alguns bancos de dados recentes como o Cassandra, o Mongo, o Neo4J e o Riak \cite{fowler:2013}.

Muitas empresas coletam e armazenam milhares de gigabytes de dados por dia, no qual a análise desses dados torna-se uma vantagem competitiva no mercado. Por isso, há uma grande necessidade de uma nova arquitetura para o gerenciamento de suporte à decisão que possa alcançar melhor escalabilidade e eficiência \cite{liu:2013}. Para auxiliar no processo de gerenciamento de suporte à decisão uma das formas mais utilizadas é a criação de um ambiente data warehousing que é responsável por providenciar informações estratégicas e esquematizadas a respeito do negócio \cite{dayal:1997}.

Segundo a definição de \cite{kimball:2002}, data warehouse (DW) é uma coleção de dados para o processo de gerenciamento de suporte à decisão orientado a assunto, integrado, variante no tempo e não volátil. Os dados de diferentes fontes de sistemas são processados em um data warehouse central através da Extração, Transformação e Carga (ETL) de maneira periódica. 

Ferramentas de ETL são sistemas de software responsáveis por extrair dados de diversas fontes, transformar e customizar os dados e inseri-los no data warehouse. Comumente, esses processos são executados periodicamente, onde a otimização do seu tempo de execução torna-se importante \cite{vassiliadis:2005}.

O projeto de ETL consome cerca de 70\% dos recursos de implantação de um DW, pois desenvolver esse projeto é crítico e custoso, tendo em vista que gerar dados incorretos pode acarretar em más decisões. Porém, por algum tempo pouca importância foi dada ao processo de ETL pelo fato de ser visto somente como uma atividade de suporte aos projetos de DW. Apenas a partir do ano 2000, a comunidade acadêmica passou a dar mais importância ao tema \cite{silva:2012}.

Tradicionalmente, o DW é implementado em uma base de dados relacional, onde o dado é armazenado nas tabelas fato e tabelas dimensões, na qual forma um esquema em estrela \cite{kimball:2002}. Por isso, é comum que as ferramentas de ETL utilizadas no mercado atualmente só dêem suporte aos esquemas relacionais. Para oferecer suporte aos sistemas que necessitem utilizar um esquema não relacional de BDs NoSQL em DW, a proposta desse trabalho é especificar um framework programável, flexível e integrado para modelagem e execução de processos ETL em BDs NoSQL.

% ---
% Capitulo com exemplos de comandos inseridos de arquivo externo 
% ---
%\include{abntex2-modelo-include-comandos}
% ---

% ----------------------------------------------------------
% seção
% ----------------------------------------------------------
\section{Motivação}
% ----------------------------------------------------------

A integração de dados e os processos de ETL são procedimentos cruciais para a criação de data warehouses e sistemas BI (business intelligence). Porém, os sistemas para ETL e integração de dados são tradicionalmente desenvolvidos para dados estruturados em modelos relacionais que representam apenas uma pequena parte dos dados mantidos por muitas empresas \cite{darmont:2005} [Russom 2007, Pedersen 2009]. Dessa forma, existe uma demanda crescente para integrar os dados não estruturados e semi estruturados em um repositório unificado. Devido a complexidade desses dados, novos desafios estão surgindo quando lidamos com dados heterogêneos e distribuídos no ambiente de integração [Salem, 2012].

Além disso, muitas empresas encontram dificuldades para lidar com as ferramentas ETL disponíveis no mercado. Aprender a lidar com essas ferramentas pode ser muito custoso em termos financeiros e de tempo, e por isso, acabam optando desenvolver os seus processos por meio de uma linguagem de programação de propósito geral [Awad et al., 2011; Muñoz et al., 2009].

Portanto, este trabalho propõe um framework programável para desenvolvimento de sistemas de ETL que possibilita a integração de dados estruturados, não estruturados e semi estruturados armazenados em bases relacionais ou NoSQL. O framework possui um ambiente integrado para a importação e mapeamento dos dados, além da modelagem e customização dos processos de ETL. Os processos de importação e mapeamento do framework integram dados estruturados, não estruturados e semi estruturados. Esses processos possibilitam a leitura e manipulação de dados de bases NoSQL, e também o armazenamento desses dados em bases deste tipo, oferecendo uma alternativa não relacional para a construção de DWs.

Uma alternativa para organizar e manipular grandes volumes de dados sem utilizar um modelo relacional e ainda processá-los e armazená-los de maneira distribuída é fazer o uso de BDs NoSQL \cite{scabora:2016}. Com isso, surge a necessidade de se promover meios para o uso desses BDs em DWs. 

As pesquisas presentes na literatura sobre extração de dados em BDs NoSQL mostram que não há uma ferramenta que seja integrada para o uso de BDs NoSQL, as ferramentas existentes no mercado apenas oferecem a possibilidade para alguns SGBDs NoSQL, ficando a cargo da equipe de implantação do projeto de DW todo o trabalho de modelagem e programação ao se utilizar BDs NoSQL [colocar ref das pesquisas].

\cite{silva:2012} aponta em sua pesquisa que muitas empresas evitam ferramentas de ETL disponíveis no mercado, e adotam o desenvolvimento dos processos a partir de uma linguagem de programação de propósito geral, pelo fato dessas ferramentas terem uma longa curva de aprendizagem e grande complexidade no seu uso.

O aumento do uso de banco de dados com esquemas não relacionais baseados no paradigma NoSQL e a falta de uma ferramenta programável, flexível e integrada, independente de plataforma que dê suporte à extração, transformação e carga em data warehouses para esses esquemas é a grande motivação deste trabalho.

Dessa forma, encontrar uma solução que seja programável, flexível e integrada para extração, transformação e carga dos dados em BDs NoSQL é a proposta deste trabalho.





% ----------------------------------------------------------
% Seção
% ----------------------------------------------------------
\section{Objetivos}

O objetivo principal desta pesquisa é especificar um framework programável, flexível e integrado para modelagem e execução de processos ETL de banco de dados estruturados, não estruturados e semi estruturados sob os modelos relacionais e NoSQL. Os objetivos específicos são detalhados a seguir.

\subsection{Objetivo Específico}

Este trabalho de dissertação tem como um dos objetivos específicos apresentar os componentes do framework ETL4NoSQL, bem como suas funcionalidades. Outro objetivo deste trabalho é realizar um estudo experimental de software a fim de caracterizar as principais funcionalidades das ferramentas de ETL na manipulação de dados estruturados, semi estruturados e não estruturados. O estudo experimental poderá comparar o framework proposto, suas vantagens e desvantagens, em relação às ferramentas de ETL encontradas na literatura.

%O primeiro objetivo específico desta pesquisa é estender a proposta do framework para facilitar a carga de dados de dois sistemas de BD NoSQL distintos baseado no mesmo paradigma NoSQL em um DW relacional modelados pelo esquema estrela, tendo em vista que este é o esquema de dados dimensionais mais recomendado pela literatura \cite{kimball:2002} \cite{Inmon: 2002}. O outro objetivo específico é ao invés de dar carga em um DW relacional fazer uso do mesmo sistema em um DW NoSQL, seguindo a metodologia adotada por \cite{chevalier:2015} em seu trabalho de pesquisa. Para isso, desenvolvemos dois frameworks especializados a partir do ETL4NoSQL em conformidade às peculiaridades dos processos de ETL nessas duas áreas de aplicação, os quais também são objetos de validação do ETL4NoSQL.

\section{Contribuições}

Uma das contribuições deste trabalho é fornecer um framework programável, flexível e integrado que auxilia na modelagem e execução dos processos de ETL em bases de dados estruturadas, semi estruturadas e não estruturadas, denominado ETL4NoSQL. Assim, é possível extrair, integrar e carregar dados que estão armazenados em diversas estruturas como é o caso dos bancos de dados NoSQL, ou até mesmo, repositórios de dados textuais e banco de dados relacionais em um único repositório. O ETL4NoSQL é um recurso valioso, principalmente para os desenvolvedores responsáveis pela fase de ETL, onde muitos encontram dificuldades para lidar com as ferramentas ETL disponíveis no mercado. 

Outra contribuição desta pesquisa é apresentar, por meio de um estudo experimental, as principais características, de acordo com algumas ferramentas de ETL presentes na literatura, bem como possíveis melhorias, vantagens e desvantagens, em suas funcionalidades.
 
\section{Organização do Trabalho}

Estae trabalho está organizado de acordo com a seguinte estrutura:

\begin{itemize}
	\item \textbf{Capítulo 2 (Fundamentação Teórica):} apresenta uma revisão da literatura dos principais assuntos abordados neste trabalho. Serão tratados temas a respeito de ETL, banco de dados NoSQL, Frameworks e estudo experimental de software.
	
	\item \textbf{Capítulo 3 (O Framework ETL4NoSQL):} descreve os requisitos, arquitetura e componentes do framework exposto neste trabalho.

	\item \textbf{Capítulo 4 (Estudo Experimental de Software):} expõe o roteiro da experimentação de software para ferramentas de ETL. Define o objetivo, planejamento, operação e resultado do estudo.
	
	\item \textbf{Capítulo 5 (Considerações Finais):} expressa as limitações e ameaças à validade do trabalho, considerações finais e sugere de trabalhos futuros.	
	
\end{itemize}

%As pesquisas passaram a apontar problemas como complexidade, longa curva de aprendizagem, notações proprietárias, custo e tempo de implantação das ferramentas atuais. Além disso, é impossível oferecer um pacote fechado com todas as possibilidades de transformações exigidas pelos processos de ETL. Para sanar essas dificuldades, propostas de modelagens conceituais e lógicas foram apresentadas e Notação de Modelagem para Processo de Negócio (BPMN) para ETL foram definidas, as quais aumentam o nível de abstração dos processos de ETL, e consequentemente, os tornam independentes da plataforma de implementação \cite{silva:2012}. 

% ---
% Capitulo de revisão de literatura
% ---
\chapter{Fundamentação Teórica}
% ---

Neste capítulo são apresentados os conceitos relacionados ao desenvolvimento desta pesquisa, bem como o embasamento teórico necessário para o entendimento do estudo. Os temas abordados são: ETL, Banco de Dados NoSQL, Frameworks, Estudo Experimental de Software e trabalhos correlatos ao tema deste trabalho.


\clearpage
% ---

\section{ETL}

ETL sigla para \textit{Extraction, Transform and Load} (Extração, Limpeza/Transformação e Carga) é conhecido na literatura por definir processos que permitem a integração de dados, centralizando-os numa base destino facilitando o gerenciamento e análise dos dados (Kimball and Caserta, 2004). O fluxo do processo de ETL inicia-se com extração dos dados a partir de uma fonte, que podem ser arquivos textuais, banco de dados relacionais ou banco de dados NoSQL. Os dados são propagados para uma Área de Processamento de Dados onde são executadas a limpeza e transformação por meio de mecanismos de ETL definidos como agregação, junção, filtro, união, entre outros. Finalmente, os dados são carregados em estruturas que podem ser data warehouses ou repositórios analíticos. 

Kimball and Caserta (2006) definem ETL em quatro macroprocessos, com 34 subsistemas. O quadro \ref{subsistemasetl} mostra os subsistemas do processo de ETL. Os quatro macroprocessos são:

\begin{itemize}
	\item Extração: Recolhe os dados dos sistemas de origem e grava na área de processamento de dados antes de qualquer reestruturação significativa. Esta etapa possui 3 subsistemas.
		
	\item Limpeza e Transformação: Envia os dados de origem, por meio de várias etapas de processamento no sistema ETL. Melhora a qualidade dos dados recebidos da fonte, mescla dados de duas ou mais fontes para criar e aplica dimensões e métricas. Esta etapa possui 5 subsistemas.
	
	\item Entrega ou Carga: Estrutura fisicamente e carrega os dados conforme desejado em DWs ou repositórios analíticos. Esta etapa possui 13 subsistemas.
	
	\item Gerenciamento: Gerencia os sistemas e processos relacionados ao ambiente ETL de forma coerente. Esta etapa possui 13 subsistemas.
\end{itemize}

	\begin{longtable}{|p{4cm}| p{11cm} |}
		\caption{Subsistemas do processo de ETL}
		\label{subsistemasetl}
		\centering
		\hline
		Etapa & Descrição\\
		\hline
		Extração & \textbf{Data Profiling:} Explora uma origem de dados para determinar seu ajuste para inclusão como uma fonte associado à limpeza e ajuste de requisitos.\\
		&  \textbf{Change Data Capture:} Isola as mudanças ocorridas nos sistemas de origem, de forma a reduzir os processos de ETL - Carga Incremental.\\
		& \textbf{Sistema de Extração:} Extração e movimentação dos dados de origem para dentro do DW, para processamento futuro.\\
		\hline
		Limpeza e Transformação &  \textbf{Data Cleasing System - Sistema de Limpeza de Dados:}  Implementa processos de qualidade de dados para identificar violações de qualidade.\\
		& \textbf{Error Event Tracking - Acompanhamento de erro:} Captura todos os ?eventos de erro?, que serão as entradas vitais para a melhoria da qualidade dos dados.\\
		& \textbf{Criação de Dimensão de auditoria:} Junta Metadados para cada Tabela Fato, como uma dimensão. Este Metadados estará disponível para a geração de aplicações de BI que visualizem  a qualidade dos dados.\\
		& \textbf{Deduplication - Tirar a duplicidade de dados:} Elimina dados redundantes de dimensões, como clientes ou produtos. Pode requerer integração cruzada entre multiplas origens e a aplicação de regras para identificar qual a versão mais correta de uma linha duplicada.\\
		& \textbf{Data Conformance - conformidade de dados:} Força o uso de atributos comuns entre as principais Conformed Dimensions versus as métricas comuns nas Tabelas Fato relacionadas.\\
		\hline
		Entrega ou Carga & \textbf{Slowly Changing Dimension (SCD) Manager:} Implementa a lógica para os atributos SCD. \\
		& \textbf{Surrogate Key Generator:} Cria as chaves substitutas (chaves de negócio) - surrogate keys independentes para cada dimensão.  \\
		& \textbf{Hierarchy Manager:} Entrega multipla e simultânea de estruturas hierarquicas na dimensão. \\
		& \textbf{Special Dimensions Manager:} Cria locais - placeholders na estrutura de ETL para sustentar os processos repetitivos específicos da organização, no desenho de dimensões específicas coma as Junk Dimensions, Mini Dimensions e indicadores de comportamento. \\
		& \textbf{Fact Table Builders:} Construção dos três tipos básicos de tabela fato: Transacional, Periódico e Cumulativo (transaction grain, periodic snapshot e accumulating snapshot). \\
		& \textbf{Surrogate Key Pipeline:} Substitui, nas dimensões, a chave natural operacional das tabelas de origem pelas chaves substitutas (Surrogate Key) que serão utilizadas para o relacionamento com as tabelas fato.  \\
		& \textbf{Multi-Valued Bridge Table Builder:} Construção e Manutenção das tabelas ponte (bridge tables) para suportar os relacionamentos multi-valorados. \\
		& \textbf{Late Arriving Data Handler:} Aplica modificações especiais nas procedures do processo padrão para lidar com tabelas fato recém definidas (late-arriving)  e dimensões. \\
		& \textbf{Dimension Manager:} Centraliza a autoridade para preparar e divulgar as dimensões conforme (conformed dimensions) para a comunidade do Data Warehouse.  \\
		& \textbf{Fact Table Provider:} Detém a administração de uma ou mais tabelas fato, e a responsabilidade de criação, manutenção e uso. \\
		& \textbf{Aggregate Builder:} Construção e manutenção de agregações que serão usadas de forma continua com tecnologias de navegação agregada para melhorar a  performance das consultas.  \\
		& \textbf{OLAP Cube Builder:} Seleciona os dados do esquema dimensional para popular os cubos OLAP. \\
		& \textbf{Data Propagation Manager:} Prepara dados conformados e integrados no servidor de apresentação do Data Warehouse, para entrega em outros ambientes, para propósitos especiais. \\
		\hline
		Gerenciamento & \textbf{Job Scheduler:} A estratégia de gerenciamento da execução dos ETLs deve ser confiável, incluindo os relacionamentos e dependências entre os ETLs. \\
		& \textbf{Backup System:} Mantem cópia do ambiente de ETL para propósito de recuperação, restart e arquivamento. \\
		& \textbf{Recovery and Restart:} Processos para recuperação do ambiente de ETL  ou processo de reinicio, em caso de eventuais falhas. \\
		& \textbf{Version Control:} Mantem arquivadas versões dos ETLs, para eventual recuperação das lógicas e metadados do 'ETL pipeline'. \\
		& \textbf{Version Migration:} Migração de uma versão completa do 'ETL pipeline' a partir do ambiente de desenvolvimento para um ambiente de testes e, finalmente, para o ambiente de produção. \\
		& \textbf{Workflow Monitor:} Garante que os processos de ETL estão sendo eficientemente executados e que as cargas iniciem precisamente nas janelas de tempo estipuladas.  \\
		& \textbf{Sorting:} Garante a fundamental alta performance nos grupos de processos de ETLs. \\
		& \textbf{Lineage and Dependency:} Identifica a origem dos dados, as localizações intermediarias, as transformações e o dado final, permitindo acompanhar de forma estruturada, a trajetória dos dados até a sua carga no Data Warehouse. \\
		& \textbf{Problem Escalation:} Estrutura de suporte que  encaminha os problemas encontrados nos processos de  ETLs (erros)  para o nível de solução apropriado. \\
		& \textbf{Paralleling and Pipelining:} Habilita ao sistema de ETL a potencializar automaticamente  o uso de recursos como múltiplos processadores ou computação em grade (grid computing) para entregas dentro dos prazos restritos. \\
		& \textbf{Security:} Garante o acesso autorizado aos ETLs e Metadados, de forma individual ou em grupos, mantendo um histórico dos acessos.\\
		& \textbf{Compliance Manager:} Suporta os requerimentos organizacionais de conformidade, através, tipicamente, da manutenção da custódia da cadeia de dados e do acompanhamento dos acessos aos dados (quem teve o acesso autorizado ao dado). \\
		& \textbf{Metadata Repository:} Captura os metadados do ETL, incluindo os metadados de processo, metadados técnicos e metadados do negócio que significam todos os metadados do ambiente de DW/BI.\\
		\hline
		
		
	\end{longtable}



\section{Bancos de Dados NoSQL}

Consistem em bancos de dados não relacionais projetados para gerenciar grandes volumes de dados e que disponibilizam estruturas e interfaces de acesso simples (Lima; Mello, 2015). Cada SGBD (Sistema Gerenciador de Banco de Dados) NoSQL possui um esquema de modelagem diferente, nos quais são divididas pela literatura em quatro categorias amplamente usadas: Chave-Valor, Orientado a Documentos, Famílias de Colunas e Baseado em Grafos ([Fowler, 2013], [Kaur; Rani, 2013]).

As principais características dos banco de dados NoSQL são: distribuído, escalabilidade horizontal, construído para grande volume de dados, BASE ao invés de ACID, modelo de dados não relacional, não suporta SQL[Fowler, 2013]. \cite{nasholm:2012}

\subsection{Banco de dados Orientados à Documentos}

Banco de dados orientados a documentos são capazes de armazenar documentos como dado. Esses documentos podem ser em qualquer formato como XML (eXtensible Markup Language), YAML (Yet Another Markup Language), JSON (JavaScript Object Notation), entre outros. Os documentos são agrupados na forma de coleções. Comparando com banco de dados relacional, as coleções são como tabelas e os documentos como os registros. Porém, a diferença entre eles é que cada registro na tabela do banco relacional tem o mesmo número de campos, enquanto que na coleção do banco de dados orientado a documentos, podem ter campos completamente diferentes (Kaur; Rani, 2013).

Existem mais de 15 banco de dados orientados a documentos disponíveis e os mais utilizados são MongoDB, CouchDB e o RavenDB (Kaur; Rani, 2013).

\subsection{Banco de dados Famílias de Colunas}

Banco de dados baseados em Famílias de Colunas são desenvolvidos para abranger três áreas: número enorme de colunas, a natureza esparsa dos dados e frequentes mudanças no esquema. Os dados em Famílias de colunas são armazenados em colunas de forma contínua, enquanto que em bancos de dados relacionais as linhas é que são contínuas. Essa mudança faz com que operações como agregação, suporte para ad-hoc e consultas dinâmicas se tornem mais eficientes (Kaur; Rani, 2013).

A maioria dos bancos de dados baseados em Famílias de Colunas são também compatíveis com o framework MapReduce, no qual acelera o processamento de enorme volume de dados pela distribuição do problema em um grande número de sistemas. Os bancos de dados  de Família de Colunas open-source mais populares são Hypertable, HBase e Cassandra (Kaur; Rani, 2013).

\subsection{Banco de dados Baseado em Grafos}

Bancos de dados baseado em Grafos são como uma estrutura de rede contendo nós e arestas, onde as arestas interligam os nós representando a relação entre eles. Comparando com o modelo Entidade-Relacionamento, o nó corresponde à entidade, a propriedade do nó à um atributo, a relação entre as entidades ao relacionamento entre os nós. Nos bancos de dados relacionais as consultas requerem atributos de mais de uma tabela resultando numa operação de junção, por outro lado, bancos de dados baseado em Grafos são desenvolvidos para encontrar relações dentro de uma enorme quantidade de dados rapidamente, tendo em vista que não é preciso fazer junções, ao invés disso, ele fornece indexação livre de adjacência (Kaur; Rani, 2013).

\subsection{Banco de dados Chave-Valor}

Em Bancos de dados Chave-Valor os dados são organizados como uma associação de vetores de entrada consistindo em pares de chave-valor. Cada chave é única e é usada para recuperar os valores associados a ele. Esses bancos de dados podem ser visualizados como um banco de dados relacional contendo múltiplas linhas e apenas duas colunas: chave e valor. Buscas baseadas em chaves resultam num baixo tempo de execução, além disso, os valores podem ser qualquer coisa como objetos, hashes, entre outros (Kaur; Rani, 2013).

Os bancos de dados Chave-Valor mais populares são Riak, Voldemort e Redis (Kaur; Rani, 2013).


\section{Frameworks}

\textit{Frameworks} podem ser considerados aglomerados de softwares, onde estes são capazes de serem estendidos e adaptados para utilidades específicas (Taligent, 1994). Pree and Sikora (1997), consideram que  \textit{frameworks} são aplicações semi-completas e que podem ser reutilizadas para especializar produtos de software customizados. Sommerville (2013), ressalta que \textit{framework} é uma estrutura genérica estendida com o intuito de criar uma aplicação mais específica e Schimidt et al. (2004 [livro sommerville pg300]) define como sendo um conjunto de artefatos de software (como classes, objetos e componentes) que colaboram para fornecer uma arquitetura reusável.

Os \textit{frameworks} possibilitam a reusabilidade de projeto, bem como ao reúso de classes específicas, pois fornecem uma arquitetura de esqueleto para a aplicação, que é definida por classes de objetos e suas interações. As classes são reusadas diretamente e podem ser estendidas usando-se recursos, como a herança (Sommerville, 2013). 

Fayad e Schmidt (1997), separam os \textit{frameworks} em três principais classes: de infraestrutura de sistema, de integração de \textit{middleware} e de aplicações corporativas. \textit{Frameworks} de infraestrutura de sistema apoiam o desenvolvimento de infraestruturas, como comunicações, interfaces de usuários e compiladores. Já os \textit{frameworks} de integração de \textit{middleware} são um conjunto de normas e classes de objetos associados que suportam componentes de comunicação e troca de informações. E finalmente, os \textit{frameworks} de aplicações corporativas estão relacionados com domínios de aplicação específicos, como sistemas financeiros. Eles incorporam conhecimentos sobre o domínios de aplicações e apoiam o desenvolvimento para o usuário final.

Muitas vezes, os \textit{frameworks} são implementações de padrões de projeto, como por exemplo o \textit{framework} MVC. A natureza geral dos padrões e o uso de classes abstratas e concretas permitem a extensibilidade (Sommerville, 2013).

Para estender um \textit{framework}

 


\section{Estudo Experimental de Software}

Segundo Travassos (2002), a experimentação é o centro do processo científico, por meio dos experimentos que é possível verificar teorias, explorar fatores críticos e formular novas teorias. O autor reforça ainda a necessidade de avaliar novas invenções e sugestões em comparação com as existentes.

Para Wohlin00, existem quatro métodos relevantes para experimentação em Engenharia de Software: científico, de engenharia, experimental e analítico. 

O paradigma indutivo, ou método científico, observa o mundo, pode ser utilizado quando se quer entender o processo, produto de software, ambiente. Ele mede e analisa, verifica as hipóteses do modelo ou teoria.  Já o método de engenharia observa as soluções existentes, é uma abordagem baseada na melhoria evolutiva, modifica modelos de processos ou produtos de softwares existentes com propósito de melhorar os objetos de estudo. O método experimental é uma abordagem baseada na melhoria revolucionária. Ela sugere um modelo, não necessariamente baseado em um existente, aplica o método qualitativo e/ou quantitativo, faz a experimentação, analisa e repete o processo. Por fim, o método analítico sugere uma teoria formal, é um método dedutivo que oferece uma base analítica para o desenvolvimento de modelos (Travassos, 2002).

Travassos (2002) sugere que a abordagem mais apropriada para a experimentação na área de Engenharia de Software seja o método experimental, pois considera a proposição e avaliação do modelo com os estudos experimentais.

Os principais objetivos relacionados à execução de um estudo experimental de software são: caracterização, avaliação, previsão, controle e melhoria a respeito de produtos, processos, recursos, modelos e teorias.

Os elementos principais do experimento são: as variáveis, os objetos, os participantes, o contexto do experimento, hipóteses e o tipo de projeto do experimento.

Esta pesquisa de dissertação considera a execução do estudo experimental de software para caracterizar, avaliar e propor melhorias ao framework ETL4NoSQL. O objetivo principal da aplicação do experimento é definir se o framework proposto é uma ferramenta adequada para auxiliar no desenvolvimento de processos de ETL em dados estruturados, semi estruturados e não estruturados. Os participantes escolhidos foram as principais ferramentas de ETL encontradas na literatura. Os questionários utilizados para a coleta de dados são baseadas nos requisitos mínimos considerados pela literatura para ferramentas de ETL.


\section{Trabalhos Correlatos}
Esta seção aborda os trabalhos que são correlatos a esta pesquisa, bem como descreve como estes trabalhos diferem do realizado
por esta pesquisa.

ARKTOS II: modela os processos de ETL

ETLMR: lida com os processos de ETL utilizando MapReduce

PygramETL: 

CloudETL:

P-ETL:

Big-ETL: Foca na paralelização e distribuição.

FramETL

Pentaho

Talend Studio for Data Integration

CloverETL

Oracle Data Integrator (ODI)





% ---


%\lipsum[2-3]

\clearpage

% ----------------------------------------------------------
% PARTE
% ----------------------------------------------------------
%\part{Resultados}
% ----------------------------------------------------------

% ---
% primeiro capitulo de Resultados
% ---
\chapter{O Framework ETL4NoSQL}
% ---
Neste capítulo são apresentados os conceitos do framework ETL4NoSQL, que consiste numa plataforma de software para desenvolvimento de sistemas de ETL, mais especificamente uma ferramenta que auxilia a construção de processos de ETL buscando apoiar a modelagem e o desempenho dos processos. 

O ETL4NoSQL oferece um ambiente integrado para modelar processos de ETL e implementar funcionalidades utilizando uma linguagem de programação independente de uma GUI (\emph{Graphical User Interface} - Interface Gráfica do Usuário).


Para a especificação do framework proposto foram definidas as estruturas de dados dos ambientes de origem, destino e da área de processamento de dados e suas respectivas linguagens de manipulação de dados, e também, as principais funcionalidades dos sistemas de ETL, chamados mecanismos de ETL. Para realizar os processos de ETL, por meio de seus mecanismos, foi definido um controlador de operações que é capaz de se comunicar com os ambientes e os mecanismos de ETL. 

A seguir, são detalhados os requisitos de software, a arquitetura do sistema e a estrutura dos componentes utilizados no desenvolvimento do framework.

\clearpage
% ---
\section{Requisitos de software do ETL4NoSQL}


Requisitos de software são descrições de como o sistema deve se comportar, definidos durante as fases iniciais do desenvolvimento do sistema como uma especificação do que deveria ser implementado (SOMMERVILLE, 1997). Os requisitos podem ser divididos em funcionais e não funcionais, onde o primeiro descrevem o que o sistema deve fazer, ou seja, as transformações a
serem realizadas nas entradas de um sistema, a fim de que se produzam saídas, já o outro expressa as características que este software vai apresentar.(SOMMERVILLE e SAWYER, 1997). 

O ETL4NoSQL é um framework que tem como principal objetivo auxiliar na criação de processos de ETL ao se utilizar diversas estruturas de armazenamento de dados. Um sistema de software pode ter seus dados armazenados em bases relacionais, que seguem o modelo entidade e relacionamento, ou não relacionais, onde esta possui pouca definição de esquema, não segue um modelo específico e são regularmente chamados de NoSQL. As bases NoSQL possuem quatro paradigmas frequentemente utilizados: Chave-Valor, Família de Colunas, Documentos e Grafo.

As bases de dados relacionais utilizam uma linguagem de gerenciamento de dados padrão conhecida por SQL (Structure Query Language), porém as bases de dados NoSQL não possuem uma linguagem em comum, como as relacionais, cada estrutura de armazenamento possui sua própria linguagem de gerenciamento de dados. Por isso, é essencial que haja um mecanismo que integre a leitura e escrita dos diversos SGBDs NoSQL. 

Outra importante características são os processos de ETL que possuem quatro etapas básicas: extração, limpeza/transformação e carga (Kimball and Caserta, 2004). O fluxo do processo de ETL inicia-se com a extração dos dados a partir de uma fonte, que podem ser bases de dados relacionais, bases NoSQL ou arquivos textuais. A partir da extração, os dados passam para uma Área de Processamento de Dados (APD), onde é possível executar processos de limpeza e transformação por meio de mecanismos de junção, filtro, união, agregação e outros. Finalmente, os dados podem ser carregados em estrutura de dados como repositórios analíticos, data warehouses, ou até mesmo em arquivos Linguagem de Marcação Flexível (XML).

Dessa forma, o ETL4NoSQL possui um ambiente que importa os dados dos diversos SGBDs NoSQL, de arquivos textuais, além dos SGBDs relacionais, e que faz a leitura e escrita dos dados permitindo a execução dos processos de ETL. No quadro \ref{requisitos} é apresentado os principais requisitos elencados do ETL4NoSQL. Foi definido como importante as prioridades que são imprescindíveis para o desenvolvimento e funcionamento do framework, e desejável as funcionalidades que aprimoram o uso do framework, porém não interferem no seu principal objetivo.

\begin{table*}[ht!]
  		\centering
  		\caption{Requisitos do ETL4NoSQL}
		\label{requisitos}
  		\begin{tabular}{|p{11cm}| p{2cm} |}
    			\hline
    			Requisito & Prioridade\\
			\hline
			 O sistema deve importar os dados de diversas bases relacionais e não relacionais & Importante\\
    			\hline
    			O sistema deve permitir a leitura e escrita dos dados importados & Importante\\
    			\hline
			O sistema deve permitir mapear os dados no modelo relacional & Importante\\
			\hline
			O sistema deve permitir mapear os dados em quaisquer modelo desejado pelo usuário & Importante\\
			\hline
			O sistema deve possuir os mecanismos ETL mais conhecidos na literatura & Importante\\
			\hline
			O sistema deve possibilitar a criação de novos mecanismos ETL desejado pelo usuário & Importante\\
			\hline
			O sistema deve possuir um ambiente que possibilite a execução dos mecanismos de ETL em operações & Importante\\
			\hline
			O sistema deve permitir o reutilização dos seus mecanismos para vários cenários & Importante\\
			\hline
			O sistema deve permitir processamento distribuído & Desejável\\
			\hline
			O sistema deve permitir a importação de dados a partir de uma nuvem & Desejável\\
			\hline
			
					
  		\end{tabular}
	\end{table*}

O modelo de processo do funcionamento da ferramenta ETL4NoSQL, baseado nas notações da UML 2.0, é representado na figura \ref{modeloprocesso}. Esse modelo descreve o processamento dos dados nas atividades de identificação dos dados, obtenção das informações para a importação e o mapeamento dos dados para os esquemas desejados, e também, a atividade dos processos de ETL para por fim dar carga dos dados em DWs, repositórios analíticos ou em arquivos XML.
	
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.5]{fig/modelo_processo.png}
		\caption{Modelo de Processos do ETL4NoSQL}
		\label{modeloprocesso}
	\end{figure}
	
Outro modelo importante para o entendimento do fluxo de processos da ferramenta ETL4NoSQL é o diagrama de atividades, que de acordo com a UML 2.0 tem como objetivo mostrar o fluxo de atividades em um único processo. O diagrama mostra como um atividade depende uma da outra. Na figura \ref{diagramaatividades} o diagrama mostra a interação dos componentes ao executar um processo de ETL, onde o estágio inicial é a importação dos dados seguido pelo mapeamento, após a obtenção dos dados necessários é possível a execução dos diversos processos de ETL em uma área de processamento para finalmente os dados serem exportados para base de destino.
	%% utilizar diagrama de fluxo de dados para descrever os requisitos do sistema e diagrama de interações


%%construir um diagrama de atividades da execução de um processo de ETL
	\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{fig/diagrama_atividades.png}
	\caption{Diagrama de Atividades do ETL4NoSQL}
	\label{diagramaatividades}
\end{figure}

\section{Arquitetura do ETL4NoSQL}


Sommerville (2007), define o projeto de arquitetura como um processo criativo em que se tenta organizar o sistema de acordo com os requisitos funcionais e não funcionais. Um estilo de arquitetura é um padrão de organização de sistema (Garlan e Shaw, 1993; Sommerville, 2007), como uma organização cliente-servidor ou uma arquitetura em camadas. Porém, a arquitetura não necessariamente utilizará apenas um estilo, a maioria dos sistemas de médio e grande porte utilizam vários estilos. Para Garlan e Shaw, há três questões a serem definidas na escolha do projeto de arquitetura, a primeira é a escolha da estrutura, cliente-servidor ou em camadas, que permita atender melhor aos requisitos. A segunda questão é a respeito da decomposição dos subsistemas em módulos ou em componentes. E por fim, deve-se tomar a decisão de sobre como a execução dos subsistemas é controlada. A descrição da arquitetura pode ser representada graficamente utilizando modelos informais e notações como a UML (Clements, et al., 2002; Sommerville, 2007).

A arquitetura do ETL4NoSQL, representada graficamente na figura \ref{arquitetura}, é baseada no requisito de reutilização. A possibilidade do reuso, reduz o trabalho repetitivo na implementação de componentes e o custo de manutenção (Szyperski, et al.2002), e sua estrutura é em camadas, onde há a camada de sistema e a camada de interface. A camada de sistema lida com todas as operações internas e a camada de interface faz toda a interligação do sistema com o ambiente externo. A decomposição dos subsistemas do ETL4NoSQL é em componentes, pois componentes podem ser subsistemas ou simples objetos que podem ser reusados (Sommerville, 2007). Os componentes que integram o framework e representados na figura \ref{arquitetura} são os componentes de importação, mapeamento, mecanismos ETL e Operações. Estes componentes serão melhor detalhados na seção seguinte.


\begin{figure}[h!]
\centering
\includegraphics[scale=0.3]{fig/arquitetura_camadas.png}
\caption{Arquitetura do Framework ETL4NoSQL}
\label{arquitetura}
\end{figure}

\section{Componentes do ETL4NoSQL}

A engenharia de software baseada em componentes é uma abordagem fundamentada em reuso para desenvolvimento de sistemas de software, ela envolve o processo de definição, implementação e integração ou composição de componentes independentes não firmemente acoplados ao sistema. Os componentes são independentes, ou seja, não interferem na operação uns dos outros e se comunicam por meio de interfaces bem definidas, os detalhes de implementação são ocultados, de forma que as alterações de implementação não afetam o restante do sistema (Sommerville, 2007). Segundo \cite{sametinger:1997}, componentes são uma parte do sistema de software que podem ser identificados e reutilizados, onde descrevem ou executam funções específicas e possuem interfaces claras, documentação apropriada e a possibilidade de reuso bem definida. Ainda de acordo com o autor, um componente deve ser autocontido, identificável, funcional, possuir uma interface, ser documentado e ter uma condição de reuso. 

De acordo com os requisitos do ETL4NoSQL, foi possível identificar quatro importantes funcionalidades que podem ser definidas como componentes do sistema, a funcionalidade de importação, mapeamento de dados, mecanismos de ETL e o controlador de operações. Os componentes do ETL4NoSQL e suas características são apresentados nas seções seguintes, seguindo as características de componentes adotadas por \cite{heineman:2001}.

%%adicionar modelo de dados e modelo de fluxo de dados
 
 \subsection{Componente de Importação}
 
Um dos objetivos do framework ETL4NoSQL é possibilitar a integração de várias estruturas de dados, relacionais ou não relacionais, presentes nos sistemas modernos. Para isso, a ferramenta deve permitir a leitura e escrita dos diversos SGBDs existentes que aplicam essas estruturas. A solução encontrada para isso foi desenvolver um componente programável que possibilite a importação dos dados por meio de inserção de parâmetros em linha de comando. Este componente, por ser criado utilizando o paradigma de orientação a objetos, permite também sua extensão, por meio de especialização, para que atenda a especificidade de cada cenário. As características do componente são apresentadas a seguir.
 
 \begin{itemize}
	\item[a)] Interface: Componente responsável pela importação dos dados da base origem.
	
	\item[b)] Nomeação: Import.
	
	\item[c)] Metadados: Este componente contém as informações da base origem como a linguagem de manipulação de dados e meios para estabelecer a conexão com a base, requer uma interação com a interface para o usuário disponibilizar as informações e fornece os dados importados para outros componentes.
	
	\item[d)] Interoperabilidade: Oferece comunicação com outros componentes por meio dos métodos listAll e userData.
	
	%\item[e)] Composição: 

	
	\item[e)] Customização: Este componente permite customizar as formas de apresentar os dados importados, de acordo com a necessidade de cada sistema.
	
	\item[f)] Suporte a evolução: Possibilita o suporte aos métodos de acordo com as mudanças de conexões e manipulações de bases de dados futuras.
	
	\item[g)] Empacotamento e utilização: Os métodos são encapsulados e podem  ser utilizados pela importação de sua classe e a interface com o usuário é por meio de linha de comando.

 \end{itemize}
 
 \subsection{Componente de Mapeamento}
 
 Para viabilizar a organização dos dados em vários tipos de esquemas desejáveis pelo usuário o ETL4NoSQL oferece o componente de mapeamento. Este componente permite definir o esquema dos dados de acordo com a necessidade da aplicação almejada pelo usuário. Por meio de parâmetros de inserção em linha de comando é possível utilizar os esquemas de dados pré-definidos pelo componente, mas também, por utilizar o paradigma de orientação a objetos e as características de reusabilidade dos componentes, é possível especializar e customizar os esquemas conforme a conveniência do usuário.
 
  \begin{itemize}
	\item[a)] Interface: Componente responsável por gerar o mapeamento dos dados oferecidos pelo componente de importação para um esquema relacional.
	
	\item[b)] Nomeação: Map.
	
	\item[c)] Metadados: Este componente requer os dados de uma base de dados para efetuar o mapeamento.
		
	\item[d)] Interoperabilidade: Oferece comunicação com outros componentes por meio dos métodos importData e listMap.
	
	%\item[e)] Composição:
	
	
	\item[e)] Customização: É possível customizar as regras de mapeamento para outros esquemas de dados.
	
	\item[f)] Suporte a evolução: Possibilita o suporte aos métodos de acordo com a necessidade de alterar os esquemas dos dados.
	
	\item[g)] Empacotamento e utilização: Os métodos são encapsulados e podem  ser utilizados pela importação de sua classe e a interface com o usuário é por meio de linha de comando.

 \end{itemize}
 
  
   \subsection{Componente de Mecanismos de ETL}
   
O ETL4NoSQL é um framework de ETL que possibilita a integração de várias estruturas de dados, por isso ele deve apresentar mecanismos que viabilizem as principais operações de ETL conhecidas pela literatura. Dessa forma, para disponibilizar as operações de ETL, o ETL4NoSQL possui um componente de mecanismos de ETL que permite executar processos de ETL como extração, limpeza/transformação e carga de dados. Além das operações básicas de ETL, o componente permite a especialização e criação de mecanismos permitindo a customização das operações de ETL conforme a necessidade do usuário.
   
  \begin{itemize}
	\item[a)] Interface: Componente que contém métodos que realizam as principais operações de ETL presentes na literatura. 
	
	\item[b)] Nomeação: MechanismETL.
	
	\item[c)] Metadados: Este componente requer dados de controle para realizar as operações por meio de seus métodos.
		
	\item[d)] Interoperabilidade: Oferece comunicação com outros componentes por meio dos métodos exec e process.
		
	%\item[e)] Composição:
	
	
	\item[e)] Customização: É possível customizar e criar mecanismos de acordo com a necessidade de cada processo de ETL.
	
	\item[f)] Suporte a evolução: Deve possibilitar o suporte aos métodos de acordo com a necessidade de alterar os esquemas dos dados.
	
	\item[g)] Empacotamento e utilização: Os métodos deverão ser encapsulados e poderão ser utilizados pela importação de sua classe e a interface com o usuário será por meio de linha de comando.

 \end{itemize}
 
    \subsection{Componente de Operações}
    
    Para proporcionar o controle dos processos de ETL executados pelo framework, o ETL4NoSQL possui o componente de operações. Este componente é responsável pelo controle das operações dos processos de ETL, ele assegura a execução dos mecanismos de ETL de acordo com a necessidade do usuário. É possível também, customizar e especializar as operações deste componente.
 
  \begin{itemize}
	\item[a)] Interface: Componente responsável por criar e executar processos de ETL.
	
	\item[b)] Nomeação: Componente de Operação.
	
	\item[c)] Metadados: Este componente deverá possibilitar a comunicação com o componente de mecanismos de ETL e deverá criar e executar processos de ETL.
	
	\item[d)] Interoperabilidade: Deve possibilitar a comunicação entre outros componentes.
	
	%\item[e)] Composição:

	
	\item[e)] Customização: É possível customizar os processos de ETL criados.
	
	\item[f)] Suporte a evolução: Deve possibilitar o suporte aos métodos de acordo com a necessidade de alterar os processos.
	
	\item[g)] Empacotamento e utilização: Os métodos deverão ser encapsulados e poderão ser utilizados pela importação de sua classe e a interface com o usuário será por meio de linha de comando.

 \end{itemize}


% ---

%\lipsum[21-22]

% ---
% segundo capitulo de Resultados

% ---
% 

%\section{Ambiente de Programação}

%Este capítulo consiste na apresentação do ambiente de programação do ETL4NoSQL. Ele foi desenvolvido utilizando a linguagem de programação orientada a objetos Python. É demonstrado também os aspectos de implementação, as classes de software e as instanciações dos objetos das classes. As classes são interfaces de programação orientada a objetos fundamentais para o modelo de abstração de frameworks, e as classes deste trabalho serão utilizadas para a importação, mapeamento de BDs NoSQL e criação de processos de ETL a partir desses BDs.

%\newpage

%\section{Implementação}

%A implementação do ETL4NoSQL foi feita utilizando a linguagem de programação orientada a objetos Python. A escolha dessa linguagem justifica-se pelo fato dela utilizar o paradigma de orientação a objetos que é adequada para a implementação dos padrões de projeto desenvolvidos na proposta deste trabalho. Além disso, Python tem uma sintaxe de fácil aprendizado e pode ser usada em diversas áreas, como Web e computação gráfica. Ela é uma linguagem de alto nível interpretada, completamente orientada a objetos e também é um software livre.

%Assim, a implementação do framework foi baseada nos princípios do design orientado a objetos de inversão de controle, onde determina que os módulos de alto nível não devem ser dependentes de módulos de baixo nível, e sim, de abstrações, ou seja, os detalhes devem depender das abstrações. Esse princípio sugere que dois módulos não devem ser ligados diretamente, pois devem estar desacoplados com uma camada de abstração entre eles. Para suprir esse princípio, o ETL4NoSQL tem uma classe abstrata para o Esquema de Dados, que utiliza dos mesmos comportamentos, para as diversas variações de esquemas que os paradigmas NoSQL possui, porém aplicados de acordo com a especificidade de cada um. Outro princípio importante utilizado é o da segregação de interfaces onde os usuários não devem ser forçados a depender de interfaces que não necessitam, deve-se escrever interfaces enxutas com métodos que sejam específicos da interface. 

%Portanto, o framework foi dividido em interfaces de importação, mapeamento dos BDs NoSQL, mecanismos e operações de processos de ETL.
%As ferramentas utilizadas para implementação do ETL4NoSQL foram:

%\begin{itemize}
%	\item Notebook com sistema operacional MacOS X; processador de 2,5 GHz Intel Core i5; e memória 12 GB 1333 MHz DDR3;
	
%	\item Python 2.7: Linguagem de programação orientada a objetos. \newline Disponível em: https://www.python.org/download/releases/2.7/;
	
%	\item LiClipse 3.4.0: plataforma de programação (IDE) open-source. \newline Disponível em: http://www.liclipse.com/download.html;
	
%	\item SGBD MariaDB versão 10.0.27. \newline Disponível em: https://downloads.mariadb.org/mariadb/10.0.27/;
	
%	\item SGBD Redis versão 3.2. Disponível em: https://redis.io/download;
	
%	\item SGBD Cassandra 3.0. Disponível em: http://cassandra.apache.org/download/
	
%\end{itemize}

%\section{Interfaces de Programação}

%\subsection{Módulo NoSQL}

%O módulo NoSQL é responsável por lidar com toda a parte que diz respeito ao dados modelados a partir dos paradigmas NoSQL. É neste módulo que serão feitas as importações dos dados e mapeamentos dos esquemas das bases não relacionais. A árvore de organização das classes do módulo pode ser vista na Figura \ref{nosqltree}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Árvore das Classes do Módulo NoSQL}
%			\includegraphics[scale=0.5]{fig/nosqltree.png}
%			\label{nosqltree}
%		\end{figure}

%\subsubsection{Esquema de Dados - SchemaData}

%Esquema de dados é uma classe que utiliza o padrão factory method, esse padrão permite que as interfaces criem objetos, porém a responsabilidade de criação fica a cargo da subclasse, as classes que derivam dela são as variações de esquemas existentes dos vários paradigmas de armazenamento de dados presentes na literatura. O trecho do código está ilustrado na Figura \ref{schemaDatacod}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Classe Schema Data}
%			\includegraphics[scale=0.5]{fig/schemaData.png}
%			\label{schemaDatacod}
%		\end{figure}
		
%O método createSchema é um método abstrato, e é por meio dele que as subclasses implementarão a criação dos seus esquemas de maneira personalizada.

%\subsubsection{Esquema de Dados Família de Coluna - SchemaDataColumnFamily }

%Classe do tipo ConcreteCreator derivada do Esquema de Dados onde define a criação do esquema das bases sob o paradigma NoSQL Família de coluna. Segundo Nasholm (2012), o esquema de dados do paradigma Família de Coluna é uma coleção de colunas em uma tabela. As linhas são similares às linhas do esquema relacional, exceto que todas as linhas na mesma tabela não necessariamente tem a mesma estrutura. Um valor numa célula, por exemplo, a intersecção de uma linha e uma coluna, é uma sequencia não interpretada de bit. Cada célula é versionada, significando que ela contém múltiplas versões do mesmo dado e que cada versão tem um timestamp atrelada a ela.O trecho do código está ilustrado na Figura \ref{schemaDataColumnFamily}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Classe Schema Data Column Family}
%			\includegraphics[scale=0.5]{fig/schemaDataColumnfamily.png}
%			\label{schemaDataColumnFamily}
%		\end{figure}



%\subsubsection{Esquema de Dados Documento - SchemaDataDocument}

%Esquema de Dados Documento é uma subclasse do Esquema de Dados do tipo ConcreteCreator, ela define o esquema das bases sob o paradigma NoSQL Orientado a documento. Conforme Nasholm (2012), um documento é geralmente um conjunto de campos onde o campo é um par chave-valor. Chaves são strings atomicas ou sequencia de bits, e valores também são atomicos, por exemplo, inteiros ou strings, ou complexos, por exemplo, listas, mapas, entre outros. Um armazenamento de dados de documentos pode armazenar muitos documentos ou até mesmo muitas coleções de documentos. O trecho do código está ilustrado na Figura \ref{schemaDataDocument}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Classe Schema Data Document}
%			\includegraphics[scale=0.5]{fig/schemaDataDocument.png}
%			\label{schemaDataDocument}
%		\end{figure}

%\subsubsection{Esquema de Dados Grafo - SchemaDataGraph}

%Subclasse de SchemaData, define o esquema das bases sob o paradigma NoSQL Baseada em Grafos. De acordo com Nasholm (2012),  bases de dados baseada em grafos é estruturada em grafos matemáticos. Um grafo G=(V, E) geralmente consiste em um conjunto de vertices V e um conjunto de arestas E. Uma aresta e $\in$ E é um parte de vértices (v1, v2) $\in$ V x V. Se o grafo é direto esses pares são ordenados. Os vértices do grafo são chamados de nós, e as arestas de relações. Cada nó contém um conjunto de propriedades. O trecho do código está ilustrado na Figura \ref{schemaDataGraph}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Classe Schema Data Graph}
%			\includegraphics[scale=0.5]{fig/schemaDataGraph.png}
%			\label{schemaDataGraph}
%		\end{figure}


%\subsubsection{Esquema de Dados Chave Valor - SchemaDataKeyValue}

%Subclasse derivada do SchemaData onde define o esquema das bases sob o paradigma NoSQL Chave-Valor. Para Nasholm (2012), o modelo de dados Chave Valor é baseado na abstração de dados do tipo Map. Ele contém a coleção de pares chave-valor onde todas as chaves são únicas. O trecho do código está ilustrado na Figura \ref{schemaDataKeyValue}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Classe Schema Data Key Value}
%			\includegraphics[scale=0.5]{fig/schemaDataKeyValue.png}
%			\label{schemaDataKeyValue}
%		\end{figure}
 
%\subsubsection{Sintaxe DDL - SyntaxDDL}

%Classe que utiliza o padrão factory method e define o comportamento da linguagem de definição de dados para cada tipo de SGBD e esquema de dados a serem criados, alterados ou excluídos. O trecho do código está ilustrado na Figura \ref{syntaxDDL}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Classe Syntax DDL}
%			\includegraphics[scale=0.5]{fig/syntaxDDL.png}
%			\label{syntaxDDL}
%		\end{figure}

 
%\subsubsection{Sintaxe DDL Cassandra - SyntaxDDLCassandra}
 
%Subclasse de Sintaxe DDL onde define a linguagem de definição de dados do SGBD Cassandra para criação, alteração e exclusão de esquemas com dados oriundos do SGBD Cassandra.
 
%\subsubsection{Sintaxe DML - SyntaxDML}

%Classe que utiliza o padrão factory method e define o comportamento da linguagem de manipulação de dados para cada tipo de SGBD e esquema de dados a serem manipulados. O trecho do código está ilustrado na Figura \ref{syntaxDML}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Classe Syntax DML}
%			\includegraphics[scale=0.5]{fig/syntaxDML.png}
%			\label{syntaxDML}
%		\end{figure}

%\subsubsection{Sintaxe DML Cassandra - SyntaxDMLCassandra}

%Subclasse de Sintaxe DML onde define a linguagem de manipulação de dados do SGBD Cassandra para a manipulação dos dados oriundos do SGBD Cassandra. Por meio dessa classe é possível buscar os dados da base de origem Cassandra.

%\subsubsection{Inventário - Inventory}

%Classe que define um inventário. Um inventário possui nome, descrição, dados de conexão e um conjunto de esquemas. O trecho do código está ilustrado na Figura \ref{inventory}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Classe Syntax DML}
%			\includegraphics[scale=0.5]{fig/inventory.png}
%			\label{inventory}
%		\end{figure}


%\subsubsection{Fábrica de Inventário - InventoryFactory}

%Classe que cria inventários, ela é responsável por manter e remover inventários. O trecho do código está ilustrado na Figura \ref{inventoryFactory}.

%		\begin{figure}[!h]
%			\centering
%			\caption{Classe Syntax DML}
%			\includegraphics[scale=0.5]{fig/inventoryFactory.png}
%			\label{inventoryFactory}
%		\end{figure}

%subsubsection{Importação - Import}

%Classe responsável pela importação dos dados das bases NoSQL. Ela utiliza as classes de sintaxes, esquemas, acessa ao inventário e mantém os dados importados.

%\subsubsection{Amostra - Sample}

%Classe responsável por criar o esquema da amostra que será importada pela classe de importação. Ela acessa o inventário para utilizar o esquema de dados, sintaxes e dados de conexão para criar a amostra.

%\subsubsection{Mapeamento}

%\subsubsection{Amostra Mapeada}

%subsection{Módulo ETL}

\section{Considerações Finais}

\chapter{Estudo Experimental de Software}

Este capítulo provê o roteiro de experimentação de software para ferramentas de ETL utilizando dados estruturados, semi estruturados e não estruturados. A Engenharia de Software Experimental tem como objetivo aprimorar métodos, técnicas e ferramentas de Engenharia de Software a partir de métodos experimentais (Isaque Elcio de Souza, TESE - Um sistema de Inf para Geren de Projetos Experimentais em ES). As etapas definidas no processo de experimentação em Engenharia de Software proposto por [Amaral (),Isaque Elcio de Souza, TESE ] consiste em etapas de definição, planejamento, operação, interpretação dos dados e empacotamento que serão melhor detalhados nas seções a seguir.
\clearpage

\section{Objetivos do experimento}

O objetivo principal da aplicação deste experimento é definir se o framework proposto por esta pesquisa de dissertação é uma ferramenta adequada para auxiliar no desenvolvimento de processos de ETL em dados estruturados, semi estruturados e não estruturados.

\subsection{Objetivo da Medição}

Tendo como base as ferramentas de ETL existentes na literatura, caracterizar:

\begin{enumerate}
	\item Quais as principais funcionalidades que as ferramentas de ETL oferecem:
	\begin{enumerate}
		\item essas funcionalidades manipulam dados estruturados, semi estruturados e não estruturados.
		\item  essas funcionalidades não manipulam dados estruturados, semi estruturados e não estruturados.
	\end{enumerate}
	\item Quais funcionalidades podem ser consideradas fundamentais para a produtividade na criação de processos de ETL:
	\begin{enumerate}
		\item quais necessitam manipular dados em grande escala.
		\item quais não manipulam grande volume de dados.
	\end{enumerate}
	\item Quais funcionalidades poderiam aprimorar as ferramentas de ETL.
\end{enumerate}

\subsection{Objetivos do Estudo}

\begin{itemize}
	\item Analisar as ferramentas de ETL para dados estruturados, semi estruturados e não estruturados;
	
	\item Com o propósito de caracterizar;
	
	\item Com respeito à intersecção das ferramentas de ETL existente;
	
	\item Do ponto de vista da literatura;
	
	\item No contexto de comparativo entre as ferramentas mais conhecidas no mercado atual.
\end{itemize}


\subsection{Questões}

Q1. Existem funcionalidades listadas pelas ferramentas pesquisadas que não estão presentes no ETL4NoSQL?

Métrica: A lista de funcionalidades que não estão presentes no ETL4NoSQL.

Q2. Existem funcionalidades oferecidas pelo ETL4NoSQL que não estão presentes nas ferramentas apresentadas pela literatura?

Métrica: A lista de funcionalidades que não estão presentes nas ferramentas da literatura.

Q3. Existem funcionalidades que não estão presentes no ETL4NoSQL e nas ferramentas da literatura que poderiam ser implementadas?

Métrica: A lista de funcionalidades que não estão presentes em nenhuma das ferramentas.

\section{Planejamento}

Na etapa de planejamento são definidas as hipóteses do estudo, a descrição da instrumentação, as métricas, seleção do contexto e dos indivíduos, as variáveis, a análise qualitativa e a validade do experimento. Todas elas serão descritas nas seções seguintes.

\subsection{Definição das Hipóteses}

Hipótese nula (H0): As funcionalidades oferecidas pelo ETL4NoSQL são similares às funcionalidades oferecidas pelas ferramentas presentes na literatura.

Fp - Funcionalidades do ETL4NoSQL

Fl - Funcionalidades das ferramentas da literatura

H0: Fl - (Fp $\cap$ Fl) = $\emptyset$
\newline

 Hipótese alternativa (H1): A lista de funcionalidades oferecidas pelo ETL4NoSQL é diferente da lista de funcionalidades oferecidas pelas ferramentas presentes na literatura.

Fp - Funcionalidades do ETL4NoSQL

Fl - Funcionalidades das ferramentas da literatura

H1: Fl - (Fp $\cap$ Fl) $\neq$ $\emptyset$
\newline

Hipótese alternativa (H2): A lista de funcionalidades que poderiam ser implementadas é diferente da lista de funcionalidades oferecidas pelas ferramentas na literatura e pelo ETL4NoSQL.

Fp - Funcionalidades do ETL4NoSQL

Fl - Funcionalidades das ferramentas da literatura

Fi - Funcionalidades que poderiam ser implementadas

H2: Fi - (Fp $\cap$ Fl $\cap$ Fi) $\neq$ $\emptyset$

\subsection{Descrição da instrumentação}

Para cada funcionalidade presente nas ferramentas apresentada na literatura que são consideradas fundamentais para o funcionamento dos processos de ETL pode ser encontrada no quadro \ref{instrumentacao}:

\begin{table}[ht]
	\centering
	\caption{Descrição da Instrumentação}
	\label{instrumentacao}
	\begin{tabular}{|p{5cm}| p{5cm} | p{5cm}|}
		\hline
		Presença da Funcionalidade (P) & Melhoria da Funcionalidade (M) & Utilidade da Funcionalidade (U)\\
		\hline
		 \begin{enumerate}
		 	\item Não está presente
		 	\item Está presente parcialmente
		 	\item Está presente
		 \end{enumerate} & 
	 	\begin{enumerate}
	 		\item Necessita melhorar
	 		\item Não há necessidade de melhoria
	 		\item Pode melhorar, mas não necessidade
	 	\end{enumerate} &
 	\begin{enumerate}
 			\item É útil
 			\item Não é útil
 			\item É parcialmente útil
 	\end{enumerate}\\
	\hline
				
	\end{tabular}
\end{table}

Para cada funcionalidade aplicar teste estatístico Chi-2 para definir:

se pode considerar que essa funcionalidade é fornecida;

se pode considerar que essa funcionalidade é útil;

se pode considerar que essa funcionalidade necessita de melhoria.

Resultado: N funcionalidades com valores (P; M; U) onde P - presença {0 - não presente; 1 - presente}; U - utilidade {0 - não é útil; 1 - é útil}; melhoria {0 - não necessita melhorar; 1 - necessita melhorar}.

\subsection{Métricas}

Na tabela \ref{metricas} são apresentadas as métricas utilizadas neste experimento.

\begin{table}[ht!]
	\centering
	\caption{Métricas}
	\label{metricas}
	\begin{tabular}{|p{0.5cm}| p{0.5cm} | p{0.5cm}| p{0.5cm}|p{9cm}|p{3cm}|}
		\hline
		N$\circ$ & P & M & U & Descrição da Funcionalidade & Questões\\
		\hline
		1 & 0 & 0 & 0 & Não está presente, não necessita melhorar, não é útil & N/A\\
		\hline
		2 & 0 & 0 & 1 & Não está presente, não necessita melhorar, é útil & Q3\\
		\hline
		3 & 0 & 1 & 0 & Não está presente, necessita melhorar, não é útil & N/A\\
		\hline
		4 & 0 & 1 & 1 & Não está presente, necessita melhorar, é útil & Q3\\
		\hline
		5 & 1 & 0 & 0 & Está presente, não necessita melhorar, não é útil & Q1, Q2\\
		\hline
		6 & 1 & 0 & 1 & Está presente, não necessita melhorar, é útil & Q1, Q2\\
		\hline
		7 & 1 & 1 & 0 & Está presente, necessita melhorar, não é útil & Q1, Q2\\
		\hline
		8 & 1 & 1 & 1 & Está presente, necessita melhorar, é útil & Q1, Q2\\
		\hline
		
		
		
		\end{tabular}
\end{table}	

\subsection{Seleção do contexto}

De acordo com Travassos (2002), o contexto pode ser caracterizado conforme quatro dimensões:

\begin{itemize}
	\item o processo: on-line / off-line;
	\item os participantes: ferramentas de ETL;
	\item realidade: o problema real / modelado;
	\item generalidade: específico / geral.
\end{itemize}

Nosso estudo supõe o processo off-line porque as ferramentas não estão sendo testadas durante todo o tempo da utilização, mas em certo instante. Os participantes são as ferramentas de ETL encontradas na literatura. O estudo é modelado porque as funcionalidades das ferramentas não são caracterizadas durante a resolução do problema real, mas utilizando parâmetros subjetivos (ex. presença, utilidade e necessidade). As funcionalidades do ETL4NoSQL são comparadas com as ferramentas presentes na literatura, então, o contexto possui o caráter específico.

\subsection{Seleção dos indivíduos}

Como participantes para o estudo propõe-se utilizar as ferramentas encontradas na literatura. Assume-se que esses indivíduos estão presente em diversos estudos realizados e avaliados no meio acadêmico.

Para a escolha das ferramentas utilizadas neste estudo foi levado em consideração a semelhança da finalidade do uso com a ferramenta proposta. Seria conveniente utilizar para o estudo ferramentas que tem o objetivo de auxiliar processos de ETL em diversas estruturas de dados. Dessa forma, a seleção baseou-se nas características das ferramentas.

\subsection{Variáveis}


Variável independente: A lista de funcionalidades das ferramentas encontradas na literatura.

Variáveis dependentes: 

\begin{enumerate}
	\item A similaridade entre as funcionalidades oferecidas pela ferramenta proposta e as funcionalidades encontradas nas ferramentas da literatura.
	
	Pode receber os valores: Igual, quando todas as funcionalidades tem o valor PMU = \{ 1, X, X \} (métricas 5-8);
	Diferente, quando todas as funcionalidades tem o valor PMU = \{ 0, X, X \} (métricas 1-4)
	Similar, quando não se cumprem as condições de "Igual" e "Diferente". O grau de similaridade pode ser avaliado como:
	\{ 1, X, X \} / \{ 0, X, X \} + \{ 1, X, X \} * 100\%
	
	\item A utilidade das funcionalidades similares. Mostra a parte útil das funcionalidades oferecidas pela ferramenta proposta:
	Parte útil: \{ 1, X, 1 \} / \{ 1, X, X \} * 100\%
	Parte inútil: \{ 1, X, 0 \} / \{ 1, X, X \} * 100\%
	
	\item A melhoria das funcionalidades similares. Mostra a necessidade de melhoria nas funcionalidades oferecidas pela ferramenta proposta:
	Não necessita melhorar: \{ 1, 0, X \} / \{ 1, X, X \} * 100\%
	Necessita melhorar: \{ 1, 0, X \} / \{ 1, X, X \} * 100\%
\end{enumerate}

\subsection{Análise Qualitativa}

Para analisar a informação referente às funcionalidades não oferecidas no ETL4NoSQL, mas que poderiam ser implementadas, propõe-se aplicar a análise qualitativa. Essa análise deve apresentar a lista de funcionalidades presentes nas ferramentas da literatura, que não estão presentes na ferramenta proposta, mas que são consideradas necessárias para facilitar a manipulação de dados estruturados, semi estruturados e não estruturados.
Assim, essa análise deve considerar funcionalidades com valor PMU = {0, X, X} (métricas 1-4) e a opção ''É útil'' para ''utilidade da funcionalidade''.

\subsection{Validade}

\textbf{Validade interna:} como mencionado na parte "Seleção dos indivíduos" para o estudo se propõe a utilizar ferramentas presentes na literatura, que são validadas pelo meio acadêmico. Assim, assume-se que elas são representativas para a população de ferramentas de ETL.

Além disso, para redução da influência dos fatores que não são interesse do nosso estudo e, portanto, para aumento da validade interna do estudo supõe-se utilizar dados das ferramentas mais populares da literatura, cuja a validação já tenha passado por diversas avaliações.

\textbf{Validade de conclusão:} para receber os valores da presença, utilidade e melhorias o teste binomial será utilizado. A verificação de hipótese será feita por meio de simples demonstração de presença ou não de funcionalidades nas listas que representam as variáveis independentes.

\textbf{Validade de construção:} esse estudo está caracterizado pela conformidade das funcionalidades listadas na ferramenta proposta com as funcionalidades reais necessárias para a utilização de ferramentas de ETL. As características das ferramentas de ETL presentes na literatura representa a lista de funcionalidades que uma ferramenta de ETL deve apresentar para mostrar o desempenho adequado do ponto de vista da literatura. As funcionalidades, que tem o maior relacionamento com as ferramentas de ETL do ponto de vista dos pesquisadores, foram escolhidas do conjunto total de funcionalidades das ferramentas de ETL presentes na literatura.

\textbf{Validade externa:} como foi mencionado nas partes "Seleção dos indivíduos" e "Validade interna" os participantes do estudo em geral podem ser considerados representativos para a população da literatura apresentada pela academia. Para avaliação do nível de importância das funcionalidades analisadas foi levada em consideração a frequência que a funcionalidade apareceu nas ferramentas da literatura.

Os materiais utilizados no estudo podem ser considerados representativos e "em tempo" para o problema sob análise, porque se compõem das funcionalidades de ferramentas de ETL presentes na literatura atual.

\section{Operação}

A etapa de operação ocorre após a etapa de planejamento do estudo experimental. Nela é exercido o monitoramento do experimento para garantir que ele esteja ocorrendo conforme foi planejado (Souza Isaque, 2015). Nesta seção serão apresentados os questionários do perfil da ferramenta de ETL e o de Funcionalidades.

\subsection{Questionário do Perfil da Ferramenta de ETL}

O quadro \ref{questionarioperfil} mostra as questões usadas para definir o perfil das ferramentas utilizadas como indivíduos deste experimento.

\begin{table}[ht]
	\centering
	\caption{Questionário do Perfil da Ferramenta de ETL}
	\label{questionarioperfil}
	\begin{tabular}{|p{8cm}| p{8cm}| }
		\hline
		Nome da ferramenta de ETL: & \\
		\hline
		Possui código aberto? & Sim $\bigcirc$ Não $\bigcirc$ \\
		\hline
		Possui uma marca reconhecida no mercado? & Sim $\bigcirc$ Não $\bigcirc$ \\
		\hline
		Tem como finalidade utilizar bancos de dados NoSQL? &  Sim $\bigcirc$ Não $\bigcirc$ \\
		\hline
		Possui interface gráfica? & Sim $\bigcirc$ Não $\bigcirc$ \\
		\hline
		É programável?  & Sim $\bigcirc$ Não $\bigcirc$ \\
		\hline
		É integrada? & Sim $\bigcirc$ Não $\bigcirc$ \\
		\hline
		Qual o tipo de processamento que a ferramenta executa? & Distribuído  $\bigcirc$  Centralizada  $\bigcirc$  Híbrido  $\bigcirc$ \\
		\hline
		É extensível? & Sim $\bigcirc$ Não $\bigcirc$ \\
		\hline
		Para qual finalidade a ferramenta procura auxiliar melhor os processos de ETL? & Modelagem $\bigcirc$ Desempenho $\bigcirc$ \\
		\hline
		
		
	\end{tabular}
\end{table}


\subsection{Questionário de Funcionalidades}

Sob o ponto de vista das características das ferramentas e considerando a finalidade da ferramenta indicada acima, avalie as colunas correspondentes segundo as escalas abaixo, a presença, utilidade e melhorias quanto às funcionalidades das ferramentas apresentadas nos seus respectivos trabalhos de pesquisa, das funcionalidades listadas no questionário:

\begin{table}[ht!]
	\centering
	\caption{Instrumentação para aplicar o questionário}
	\label{instrumentacao2}
	\begin{tabular}{|p{5cm}| p{5cm} | p{5cm}|}
		\hline
		Presença da Funcionalidade (P) & Melhoria da Funcionalidade (M) & Utilidade da Funcionalidade (U)\\
		\hline
		\begin{enumerate}
			\item Não está presente
			\item Está presente parcialmente
			\item Está presente
		\end{enumerate} & 
		\begin{enumerate}
			\item Necessita melhorar
			\item Não há necessidade de melhoria
			\item Pode melhorar, mas não necessidade
		\end{enumerate} &
		\begin{enumerate}
			\item É útil
			\item Não é útil
			\item É parcialmente útil
		\end{enumerate}\\
		\hline
		
	\end{tabular}
\end{table}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.8]{fig/questionario.png}
	\caption{Questionário de Funcionalidades}
	\label{questionariofuncionalidades}
\end{figure}

\section{Resultado do Estudo}

% ---
\section{Descrição}
\section{Considerações Finais}

% ---

%\lipsum[24]


% ---
% Conclusão
% ---
\chapter{Considerações Finais}
\clearpage

\section{Principais Contribuições}
\section{Discussão}
\section{Resultados}
\section{Trabalhos Futuros}
% ---

%\lipsum[31-33]



%%
%% Parte pós-textual
%%
\backmatter

% Apêndices
% Comente se não houver apêndices
\appendix

% É aconselhável criar cada apêndice em um arquivo à parte, digamos
% "apendice1.tex", "apendice.tex", ... "apendiceM.tex" e depois
% incluí-los com:
% \include{apendice1}
% \include{apendice2}
% ...
% \include{apendiceM}


% Bibliografia
% É aconselhável utilizar o BibTeX a partir de um arquivo, digamos "biblio.bib".
% Para ajuda na criação do arquivo .bib e utilização do BibTeX, recorra ao
% BibTeXpress em www.cin.ufpe.br/~paguso/bibtexpress
%\nocite{*}
\bibliographystyle{alpha}
\bibliography{minha_dissertacao_ufpe}

% Cólofon
% Inclui uma pequena nota com referência à UFPEThesis
% Comente para omitir
%\colophon

%% Fim do documento
\end{document}